"""
å­¦ä¹ è®¡åˆ’ API è·¯ç”±

å®Œæ•´åŠŸèƒ½ï¼ˆæ›¿ä»£äº‘å‡½æ•°ï¼‰ï¼š
- è·å–æ´»è·ƒè®¡åˆ’
- ä¿å­˜è®¡åˆ’
- åˆ é™¤è®¡åˆ’
- ç”Ÿæˆè®¡åˆ’
- ç”Ÿæˆé˜¶æ®µè¯¦æƒ…
- è·å–ç›®æ ‡è¾¾æˆç‡
- ç”Ÿæˆæ˜æ—¥ä»»åŠ¡
"""
import json
import re
import uuid
from datetime import datetime, timedelta, timezone
from typing import Any, Dict, List, Optional

from fastapi import APIRouter, HTTPException, Request
from fastapi.responses import StreamingResponse

from ..db.wxcloud import get_db, PlanRepository
from ..models import (
    AnalyzeMistakeRequest,
    AnalyzeMistakeResponse,
    GeneratePlanRequest,
    GeneratePlanResponse,
    GenerateTasksRequest,
    GenerateTasksResponse,
)
from ..services.ai_service import AIService
from ..services.plan_service import PlanService

router = APIRouter(prefix="/api/plan", tags=["å­¦ä¹ è®¡åˆ’"])


# ==================== å·¥å…·å‡½æ•° ====================


# é¢†åŸŸåç§°æ˜ å°„ï¼ˆä¸å‰ç«¯ app.js ä¸­çš„ studyDomains ä¿æŒä¸€è‡´ï¼‰
DOMAIN_NAMES = {
    # å‰ç«¯æ–°ç‰ˆ domain ID
    "exam_postgraduate": "è€ƒç ”",
    "exam_civil": "è€ƒå…¬",
    "exam_english": "è‹±è¯­",
    "exam_cert": "è€ƒè¯",
    "programming": "ç¼–ç¨‹",
    "other": "å…¶ä»–",
    # å…¼å®¹æ—§ç‰ˆ domain ID
    "postgraduate": "è€ƒç ”",
    "english": "è‹±è¯­å­¦ä¹ ",
    "certification": "èŒä¸šè®¤è¯",
    "academic": "å­¦ä¸šæå‡",
}


def _fix_domain_name(plan: Dict[str, Any]) -> Dict[str, Any]:
    """
    ä¿®å¤è®¡åˆ’çš„ domainName å­—æ®µï¼Œç¡®ä¿æ˜¾ç¤ºä¸­æ–‡åç§°è€Œé domain ID
    """
    if not plan:
        return plan
    
    domain_name = plan.get("domainName", "")
    domain = plan.get("domain", "")
    
    # å¦‚æœ domainName çœ‹èµ·æ¥æ˜¯ domain IDï¼ˆåŒ…å«ä¸‹åˆ’çº¿æˆ–åœ¨æ˜ å°„è¡¨ä¸­ï¼‰ï¼Œåˆ™è½¬æ¢ä¸ºä¸­æ–‡åç§°
    if domain_name in DOMAIN_NAMES:
        plan["domainName"] = DOMAIN_NAMES[domain_name]
    elif not domain_name and domain:
        # domainName ä¸ºç©ºæ—¶ï¼Œæ ¹æ® domain å­—æ®µè·å–ä¸­æ–‡åç§°
        plan["domainName"] = DOMAIN_NAMES.get(domain, domain)
    
    return plan


def _get_openid_from_request(request: Request) -> str:
    openid = request.headers.get("x-wx-openid") or request.headers.get("X-WX-OPENID")
    if not openid:
        raise HTTPException(
            status_code=401,
            detail="ç¼ºå°‘ç”¨æˆ·èº«ä»½ï¼ˆX-WX-OPENIDï¼‰ï¼Œè¯·ä½¿ç”¨ wx.cloud.callContainer å†…ç½‘è°ƒç”¨",
        )
    return openid


def _beijing_now() -> datetime:
    """è·å–åŒ—äº¬æ—¶é—´"""
    return datetime.now(timezone.utc) + timedelta(hours=8)


def _parse_duration_to_days(duration: str) -> int:
    """è§£ææ—¶é•¿å­—ç¬¦ä¸²ï¼Œè¿”å›å¤©æ•°"""
    if not duration:
        return 7
    # æå–çº¯æ—¶é•¿éƒ¨åˆ†ï¼ˆå»æ‰æ‹¬å·é‡Œçš„æ—¥æœŸèŒƒå›´ï¼‰
    pure_duration = duration.split('(')[0].split('ï¼ˆ')[0].strip()
    
    match = re.search(r'(\d+(?:\.\d+)?)\s*(å‘¨|å¤©|æœˆ|ä¸ªæœˆ)', pure_duration)
    if not match:
        return 7
    
    value = float(match.group(1))
    unit = match.group(2)
    
    if unit == 'å¤©':
        return int(value)
    elif unit == 'å‘¨':
        return int(value * 7)
    elif unit in ('æœˆ', 'ä¸ªæœˆ'):
        return int(value * 30)
    return 7


def _days_to_readable(days: int) -> str:
    """å°†å¤©æ•°è½¬æ¢ä¸ºå¯è¯»çš„æ—¶é•¿æ–‡æœ¬"""
    if days < 7:
        return f"{days}å¤©"
    elif days < 30:
        weeks = round(days / 7)
        return f"{weeks}å‘¨"
    else:
        months = days / 30
        if months < 1:
            return f"{round(days / 7)}å‘¨"
        rounded_months = round(months * 2) / 2
        if rounded_months == int(rounded_months):
            return f"{int(rounded_months)}ä¸ªæœˆ"
        return f"{rounded_months}ä¸ªæœˆ"


def _calculate_phases_with_dates(phases: List[Dict], created_at: datetime, deadline_str: str = None) -> tuple:
    """
    è®¡ç®—æ¯ä¸ªé˜¶æ®µçš„å…·ä½“æ—¥æœŸèŒƒå›´ï¼Œè¿”å›æ›´æ–°åçš„ phases å’Œ totalDuration
    
    Args:
        phases: é˜¶æ®µåˆ—è¡¨
        created_at: è®¡åˆ’åˆ›å»ºæ—¶é—´
        deadline_str: æˆªæ­¢æ—¥æœŸå­—ç¬¦ä¸²
    
    Returns:
        (updated_phases, total_duration_str)
    """
    if not phases:
        return phases, "å¾…å®š"
    
    # è®¡ç®—æ¯ä¸ªé˜¶æ®µçš„åŸå§‹å¤©æ•°
    phase_days = []
    for phase in phases:
        days = _parse_duration_to_days(phase.get("duration", ""))
        phase_days.append(days)
    
    total_original_days = sum(phase_days)
    
    # è§£ææˆªæ­¢æ—¥æœŸ
    deadline_date = None
    if deadline_str:
        try:
            deadline_date = datetime.fromisoformat(deadline_str.replace("Z", "+00:00"))
        except:
            pass
    
    # è®¡ç®—å®é™…æ€»å¤©æ•°
    if deadline_date and deadline_date > created_at:
        actual_total_days = (deadline_date - created_at).days
    else:
        actual_total_days = total_original_days
        deadline_date = created_at + timedelta(days=total_original_days)
    
    # æŒ‰æ¯”ä¾‹åˆ†é…æ¯ä¸ªé˜¶æ®µçš„å®é™…å¤©æ•°
    if total_original_days > 0:
        actual_phase_days = [
            max(1, round((d / total_original_days) * actual_total_days))
            for d in phase_days
        ]
    else:
        actual_phase_days = phase_days
    
    # è®¡ç®—æ¯ä¸ªé˜¶æ®µçš„èµ·æ­¢æ—¥æœŸå¹¶æ›´æ–° duration
    current_date = created_at
    updated_phases = []
    
    for i, phase in enumerate(phases):
        phase_start = current_date
        phase_end = phase_start + timedelta(days=actual_phase_days[i])
        
        # æ ¼å¼åŒ–æ—¥æœŸèŒƒå›´
        start_str = f"{phase_start.year}å¹´{phase_start.month}æœˆ"
        end_str = f"{phase_end.year}å¹´{phase_end.month}æœˆ"
        duration_text = _days_to_readable(actual_phase_days[i])
        
        # æ›´æ–°é˜¶æ®µä¿¡æ¯
        updated_phase = {**phase}
        updated_phase["duration"] = f"{duration_text} ({start_str}-{end_str})"
        updated_phase["startDate"] = phase_start.isoformat()
        updated_phase["endDate"] = phase_end.isoformat()
        updated_phases.append(updated_phase)
        
        current_date = phase_end
    
    # è®¡ç®—æ€»æ—¶é•¿å­—ç¬¦ä¸²
    plan_start = created_at
    plan_end = deadline_date if deadline_date else current_date
    total_duration_text = _days_to_readable(actual_total_days)
    total_duration = f"çº¦{total_duration_text}ï¼ˆä»{plan_start.year}å¹´{plan_start.month}æœˆè‡³{plan_end.year}å¹´{plan_end.month}æœˆï¼‰"
    
    return updated_phases, total_duration


def _beijing_day_range(days_offset: int = 0):
    """è·å–åŒ—äº¬æ—¶é—´æŸå¤©çš„ UTC æ—¶é—´èŒƒå›´"""
    now_utc = datetime.now(timezone.utc)
    beijing_now = now_utc + timedelta(hours=8)
    beijing_day = beijing_now.date() + timedelta(days=days_offset)
    day_start_utc = (
        datetime(beijing_day.year, beijing_day.month, beijing_day.day, tzinfo=timezone.utc)
        - timedelta(hours=8)
    )
    day_end_utc = day_start_utc + timedelta(days=1)
    return day_start_utc, day_end_utc


def _beijing_date_str(days_offset: int = 0) -> str:
    """è·å–åŒ—äº¬æ—¶é—´æ—¥æœŸå­—ç¬¦ä¸² YYYY-MM-DD"""
    today_start, _ = _beijing_day_range(days_offset)
    return (today_start + timedelta(hours=8)).date().isoformat()


def _parse_phase_duration_days(duration: str) -> int:
    """è§£æé˜¶æ®µæ—¶é•¿ä¸ºå¤©æ•°"""
    if not duration:
        return 7
    m = re.search(r"(\d+)\s*(å‘¨|å¤©|æœˆ)", str(duration))
    if not m:
        return 7
    num = int(m.group(1))
    unit = m.group(2)
    if unit == "å¤©":
        return num
    if unit == "å‘¨":
        return num * 7
    if unit == "æœˆ":
        return num * 30
    return 7


def _get_current_phase(plan: Dict[str, Any]) -> Optional[Dict[str, Any]]:
    """è·å–å½“å‰å­¦ä¹ é˜¶æ®µ"""
    phases = plan.get("phases") or []
    if not phases:
        return None

    created_at = plan.get("createdAt")
    if isinstance(created_at, dict) and "$date" in created_at:
        try:
            created_at = datetime.fromisoformat(created_at["$date"].replace("Z", "+00:00"))
        except Exception:
            created_at = None
    elif isinstance(created_at, str):
        try:
            created_at = datetime.fromisoformat(created_at.replace("Z", "+00:00"))
        except Exception:
            created_at = None

    if not created_at:
        return phases[0]

    now_utc = datetime.now(timezone.utc)
    days_since_start = int((now_utc - created_at).total_seconds() // (24 * 3600))

    accumulated = 0
    for i, phase in enumerate(phases):
        accumulated += _parse_phase_duration_days(str(phase.get("duration", "")))
        if days_since_start < accumulated:
            return {**phase, "index": i + 1}
    return {**phases[-1], "index": len(phases)}


def _calculate_remaining_days(plan: Dict[str, Any]) -> Optional[int]:
    """è®¡ç®—å‰©ä½™å¤©æ•°"""
    deadline = plan.get("deadline")
    if not deadline:
        return None
    try:
        if isinstance(deadline, str):
            deadline_date = datetime.strptime(deadline, "%Y-%m-%d").date()
        else:
            return None
        today = _beijing_now().date()
        return (deadline_date - today).days
    except Exception:
        return None


# ==================== è®¡åˆ’ç®¡ç† API ====================


@router.get("/whoami")
async def whoami(request: Request):
    """
    è·å–å½“å‰ç”¨æˆ·èº«ä»½ä¿¡æ¯
    ç”¨äºå‰ç«¯è·å–å¹¶ç¼“å­˜ openidï¼Œä»¥ä¾¿åœ¨æµå¼è¯·æ±‚ä¸­ä½¿ç”¨
    """
    openid = _get_openid_from_request(request)
    return {"success": True, "openid": openid}


@router.get("/active")
async def get_active_plan(request: Request):
    """
    è·å–å½“å‰æ´»è·ƒè®¡åˆ’ + ä»Šæ—¥ä»»åŠ¡
    """
    import logging
    logger = logging.getLogger(__name__)
    
    openid = _get_openid_from_request(request)
    db = get_db()
    plan_repo = PlanRepository(db)

    plan = await plan_repo.get_active_plan(openid)
    if not plan:
        return {"success": True, "hasActivePlan": False, "plan": None, "todayTasks": []}

    # ç¡®ä¿ plan_id æ˜¯å­—ç¬¦ä¸²æ ¼å¼
    raw_id = plan.get("_id") or plan.get("id")
    plan_id = str(raw_id) if raw_id else None
    if not plan_id:
        raise HTTPException(status_code=500, detail="å­¦ä¹ è®¡åˆ’ç¼ºå°‘ _id")

    today_str = _beijing_date_str(0)
    
    logger.info(f"[plan/active] æŸ¥è¯¢ä»Šæ—¥ä»»åŠ¡: openid={openid[:8]}***, planId={plan_id}, dateStr={today_str}")

    # æŸ¥è¯¢ä»Šæ—¥ä»»åŠ¡
    tasks = await db.query(
        "plan_tasks",
        {"openid": openid, "planId": plan_id, "dateStr": today_str},
        limit=200,
        order_by="order",
        order_type="asc",
    )
    logger.info(f"[plan/active] dateStr æŸ¥è¯¢ç»“æœ: {len(tasks)} æ¡ä»»åŠ¡")
    
    if not tasks:
        today_start, today_end = _beijing_day_range(0)
        tasks = await db.query(
            "plan_tasks",
            {
                "openid": openid,
                "planId": plan_id,
                "date": {
                    "$gte": {"$date": today_start.isoformat()},
                    "$lt": {"$date": today_end.isoformat()},
                },
            },
            limit=200,
            order_by="order",
            order_type="asc",
        )
        logger.info(f"[plan/active] date èŒƒå›´æŸ¥è¯¢ç»“æœ: {len(tasks)} æ¡ä»»åŠ¡")

    # è¡¥å……è®¡åˆ’æ´¾ç”Ÿå­—æ®µ
    plan["daysLeft"] = _calculate_remaining_days(plan)
    current_phase = _get_current_phase(plan)
    if current_phase:
        plan["currentPhase"] = current_phase
    
    # ä¿®å¤ domainName æ˜¾ç¤ºï¼ˆå°† domain ID è½¬æ¢ä¸ºä¸­æ–‡åç§°ï¼‰
    plan = _fix_domain_name(plan)

    return {
        "success": True,
        "hasActivePlan": True,
        "plan": plan,
        "todayTasks": tasks,
        "dateStr": today_str,
    }


@router.post("/save")
async def save_plan(request: Request):
    """
    ä¿å­˜å­¦ä¹ è®¡åˆ’ï¼ˆæ›¿ä»£äº‘å‡½æ•° savePlanï¼‰
    - å°†æ—§çš„ active è®¡åˆ’ç½®ä¸º archived
    - ä¿å­˜æ–°è®¡åˆ’
    """
    openid = _get_openid_from_request(request)
    db = get_db()

    try:
        body = await request.json()
    except Exception:
        raise HTTPException(status_code=400, detail="è¯·æ±‚ä½“æ ¼å¼é”™è¯¯")

    plan_data = body.get("plan") or {}
    goal = body.get("goal") or plan_data.get("goal", "")
    domain = body.get("domain") or plan_data.get("domain", "")
    deadline = body.get("deadline") or plan_data.get("deadline")
    daily_hours = float(body.get("dailyHours") or body.get("daily_hours") or 2)
    current_level = body.get("currentLevel") or body.get("current_level") or "beginner"
    personalization = body.get("personalization") or body.get("preferences") or plan_data.get("personalization") or plan_data.get("preferences") or None

    # è·å–é¢†åŸŸä¸­æ–‡åç§°
    domain_name = DOMAIN_NAMES.get(domain, domain)

    # å°†ç°æœ‰ active è®¡åˆ’ç½®ä¸º archived
    await db.update(
        "study_plans",
        {"openid": openid, "status": "active"},
        {"status": "archived"},
    )

    # ä¸ºæ¯ä¸ªé˜¶æ®µç”Ÿæˆ ID
    phases = plan_data.get("phases") or []
    for i, phase in enumerate(phases):
        if not phase.get("id"):
            phase["id"] = f"phase_{i+1}_{uuid.uuid4().hex[:8]}"
        phase["status"] = "completed"  # æ¡†æ¶å·²ç”Ÿæˆï¼Œåç»­å¯è¡¥å……è¯¦æƒ…

    now = datetime.now(timezone.utc)
    now_str = now.isoformat()
    
    # æ ¹æ®åˆ›å»ºæ—¶é—´å’Œæˆªæ­¢æ—¥æœŸè®¡ç®—æ¯ä¸ªé˜¶æ®µçš„å…·ä½“æ—¶é—´èŒƒå›´
    phases_with_dates, total_duration = _calculate_phases_with_dates(phases, now, deadline)

    new_plan = {
        "openid": openid,
        "goal": goal,
        "domain": domain,
        "domainName": domain_name,
        "deadline": deadline,
        "dailyHours": daily_hours,
        "currentLevel": current_level,
        # ç”¨äº"æ›´å¼ºä¸ªæ€§åŒ–ç”»åƒ/è®¡åˆ’å¼ºåº¦èŠ‚å¥"
        "personalization": personalization if isinstance(personalization, dict) else {},
        "status": "active",
        "progress": 0,
        "todayProgress": 0,
        "completedDays": 0,
        "phases": phases_with_dates,  # ä½¿ç”¨è®¡ç®—åçš„é˜¶æ®µï¼ˆåŒ…å«å…·ä½“æ—¥æœŸï¼‰
        "totalDuration": total_duration,  # ä½¿ç”¨è®¡ç®—åçš„æ€»æ—¶é•¿
        "dailySchedule": plan_data.get("daily_schedule") or plan_data.get("dailySchedule", []),
        "tips": plan_data.get("tips", []),
        "createdAt": {"$date": now_str},
        "updatedAt": {"$date": now_str},
    }

    plan_id = await db.add("study_plans", new_plan)
    new_plan["_id"] = plan_id

    return {"success": True, "data": {"planId": plan_id, "plan": new_plan}}


@router.post("/delete")
async def delete_plan(request: Request):
    """
    åˆ é™¤å½“å‰æ´»è·ƒè®¡åˆ’ï¼ˆç½®ä¸º deleted çŠ¶æ€ï¼‰
    """
    openid = _get_openid_from_request(request)
    db = get_db()

    # è·å–å½“å‰æ´»è·ƒè®¡åˆ’
    plan_repo = PlanRepository(db)
    plan = await plan_repo.get_active_plan(openid)
    if not plan:
        return {"success": True, "message": "æ²¡æœ‰æ´»è·ƒçš„è®¡åˆ’"}

    # ç¡®ä¿ plan_id æ˜¯å­—ç¬¦ä¸²æ ¼å¼
    raw_id = plan.get("_id") or plan.get("id")
    plan_id = str(raw_id) if raw_id else None

    # å°†è®¡åˆ’ç½®ä¸º deleted
    await db.update_by_id(
        "study_plans",
        plan_id,
        {"status": "deleted", "deletedAt": {"$date": datetime.now(timezone.utc).isoformat()}},
    )

    # åˆ é™¤å…³è”çš„ä»»åŠ¡ï¼ˆå¯é€‰ï¼šä¹Ÿå¯ä»¥ä¿ç•™å†å²è®°å½•ï¼‰
    await db.delete("plan_tasks", {"planId": plan_id})

    return {"success": True, "message": "è®¡åˆ’å·²åˆ é™¤"}


# ==================== è®¡åˆ’ç”Ÿæˆ API ====================


@router.post("/generate", response_model=GeneratePlanResponse)
async def generate_plan(request: GeneratePlanRequest):
    """
    AI ç”Ÿæˆå­¦ä¹ è®¡åˆ’
    """
    import logging
    logger = logging.getLogger(__name__)
    
    logger.info(f"[plan/generate] æ”¶åˆ°è¯·æ±‚: goal={request.goal[:50] if request.goal else ''}, domain={request.domain}")
    logger.info(f"[plan/generate] å‚æ•°: daily_hours={request.daily_hours}, deadline={request.deadline}, level={request.current_level}")
    
    try:
        result = await PlanService.generate_study_plan(
            goal=request.goal,
            domain=request.domain,
            daily_hours=request.daily_hours,
            deadline=request.deadline,
            current_level=request.current_level,
            preferences=request.preferences,
        )

        logger.info(f"[plan/generate] AI ç”Ÿæˆç»“æœ: success={result.get('success')}")
        
        if result.get("success"):
            return GeneratePlanResponse(success=True, plan=result.get("plan"))
        else:
            error_msg = result.get("error", "ç”Ÿæˆå¤±è´¥")
            logger.error(f"[plan/generate] ç”Ÿæˆå¤±è´¥: {error_msg}")
            raise HTTPException(status_code=500, detail=error_msg)

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"[plan/generate] å¼‚å¸¸: {type(e).__name__}: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"è®¡åˆ’ç”Ÿæˆå¼‚å¸¸: {str(e)}")


@router.post("/generate/stream")
async def generate_plan_stream(request: GeneratePlanRequest):
    """
    AI ç”Ÿæˆå­¦ä¹ è®¡åˆ’ï¼ˆæµå¼å“åº”ï¼‰
    
    è¿”å› Server-Sent Events æ ¼å¼ï¼š
    - data: {"type": "progress", "message": "..."} - è¿›åº¦æ›´æ–°
    - data: {"type": "content", "content": "..."} - AI åŸå§‹è¾“å‡ºç‰‡æ®µ
    - data: {"type": "result", "success": true, "plan": {...}} - æœ€ç»ˆç»“æœ
    - data: {"type": "error", "error": "..."} - é”™è¯¯ä¿¡æ¯
    - data: [DONE] - ç»“æŸæ ‡è®°
    """
    import logging
    logger = logging.getLogger(__name__)
    
    logger.info(f"[plan/generate/stream] æ”¶åˆ°è¯·æ±‚: goal={request.goal[:50] if request.goal else ''}, domain={request.domain}")
    
    async def generate():
        full_content = ""
        
        try:
            # å‘é€è¿›åº¦æ›´æ–°
            yield f"data: {json.dumps({'type': 'progress', 'message': 'æ­£åœ¨åˆ†æå­¦ä¹ ç›®æ ‡...'})}\n\n"
            
            # æ„å»º prompt
            prompt = PlanService._build_plan_prompt(
                request.goal,
                request.domain,
                request.daily_hours,
                request.deadline,
                request.current_level,
                request.preferences,
            )
            
            messages = [{"role": "user", "content": prompt}]
            
            yield f"data: {json.dumps({'type': 'progress', 'message': 'æ­£åœ¨ç”Ÿæˆå­¦ä¹ è®¡åˆ’...'})}\n\n"
            
            # æµå¼è°ƒç”¨ AI
            async for chunk in AIService.chat_stream(
                messages=messages,
                model_type="text",
                temperature=0.7,
                max_tokens=4000,
            ):
                full_content += chunk
                # å‘é€å†…å®¹ç‰‡æ®µ
                yield f"data: {json.dumps({'type': 'content', 'content': chunk})}\n\n"
            
            yield f"data: {json.dumps({'type': 'progress', 'message': 'æ­£åœ¨è§£æè®¡åˆ’ç»“æ„...'})}\n\n"
            
            # è§£æ JSON
            json_match = re.search(r'\{[\s\S]*\}', full_content)
            if json_match:
                try:
                    plan = json.loads(json_match.group())
                    logger.info(f"[plan/generate/stream] è®¡åˆ’è§£ææˆåŠŸ, phasesæ•°é‡: {len(plan.get('phases', []))}")
                    yield f"data: {json.dumps({'type': 'result', 'success': True, 'plan': plan})}\n\n"
                except json.JSONDecodeError as je:
                    logger.error(f"[plan/generate/stream] JSON è§£æå¤±è´¥: {je}")
                    yield f"data: {json.dumps({'type': 'error', 'error': f'JSONè§£æå¤±è´¥: {str(je)}'})}\n\n"
            else:
                logger.error("[plan/generate/stream] AI å“åº”ä¸­æœªæ‰¾åˆ° JSON")
                yield f"data: {json.dumps({'type': 'error', 'error': 'è®¡åˆ’æ ¼å¼é”™è¯¯ï¼Œæœªæ‰¾åˆ°æœ‰æ•ˆJSON'})}\n\n"
                
        except Exception as e:
            logger.error(f"[plan/generate/stream] å¼‚å¸¸: {type(e).__name__}: {str(e)}", exc_info=True)
            yield f"data: {json.dumps({'type': 'error', 'error': str(e)})}\n\n"
        
        yield "data: [DONE]\n\n"
    
    return StreamingResponse(
        generate(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no",
        },
    )


@router.post("/phase-detail")
async def generate_phase_detail(request: Request):
    """
    ç”Ÿæˆå­¦ä¹ é˜¶æ®µè¯¦æƒ…ï¼ˆæ›¿ä»£äº‘å‡½æ•° generatePhaseDetailï¼‰
    """
    import logging
    logger = logging.getLogger(__name__)
    
    openid = _get_openid_from_request(request)
    db = get_db()

    try:
        body = await request.json()
    except Exception:
        raise HTTPException(status_code=400, detail="è¯·æ±‚ä½“æ ¼å¼é”™è¯¯")

    plan_id = body.get("planId") or body.get("plan_id")
    phase_id = body.get("phaseId") or body.get("phase_id")

    if not plan_id or not phase_id:
        raise HTTPException(status_code=400, detail="ç¼ºå°‘ planId æˆ– phaseId")

    logger.info(f"[phase-detail] è¯·æ±‚: planId={plan_id}, phaseId={phase_id}, openid={openid[:8] if openid else 'None'}***")

    # è·å–è®¡åˆ’
    plan = await db.get_by_id("study_plans", plan_id)
    
    if not plan:
        logger.error(f"[phase-detail] è®¡åˆ’ä¸å­˜åœ¨: planId={plan_id}")
        raise HTTPException(status_code=404, detail=f"è®¡åˆ’ä¸å­˜åœ¨: {plan_id}")
    
    # å…¼å®¹æ—§ç‰ˆæ•°æ®ç»“æ„ï¼šå¦‚æœæ•°æ®è¢«åµŒå¥—åœ¨ data å­—æ®µä¸­ï¼Œåˆ™æå–å‡ºæ¥
    # è¿™æ˜¯ç”±äºä¹‹å‰ nodedb çš„ add() è°ƒç”¨ä½¿ç”¨äº†é”™è¯¯çš„ { data: ... } åŒ…è£…
    if "data" in plan and isinstance(plan.get("data"), dict) and "openid" not in plan:
        logger.warning("[phase-detail] æ£€æµ‹åˆ°æ—§ç‰ˆåµŒå¥—æ•°æ®ç»“æ„ï¼Œæ­£åœ¨æå–...")
        nested_data = plan.get("data")
        plan = {**nested_data, "_id": plan.get("_id")}
    
    plan_openid = plan.get("openid")
    logger.info(f"[phase-detail] è®¡åˆ’æŸ¥è¯¢ç»“æœ: plan_openid={plan_openid[:8] if plan_openid else 'None'}***, plan_keys={list(plan.keys())[:5]}")
    
    if plan_openid != openid:
        logger.warning(f"[phase-detail] openidä¸åŒ¹é…: request={openid[:8] if openid else 'None'}***, plan={plan_openid[:8] if plan_openid else 'None'}***")
        raise HTTPException(status_code=403, detail=f"æ— æƒè®¿é—®è¯¥è®¡åˆ’ (plan_openid={plan_openid[:8] if plan_openid else 'None'}***)")

    # æ‰¾åˆ°å¯¹åº”é˜¶æ®µ
    phases = plan.get("phases") or []
    phase = None
    phase_index = -1
    for i, p in enumerate(phases):
        if p.get("id") == phase_id:
            phase = p
            phase_index = i
            break

    if not phase:
        raise HTTPException(status_code=404, detail="é˜¶æ®µä¸å­˜åœ¨")

    # è°ƒç”¨ AI ç”Ÿæˆè¯¦æƒ…
    result = await PlanService.generate_phase_detail(
        phase_name=phase.get("name", ""),
        phase_goals=phase.get("goals", []),
        domain=plan.get("domainName") or plan.get("domain", ""),
        duration=phase.get("duration", "1å‘¨"),
    )

    if not result.get("success"):
        raise HTTPException(status_code=500, detail=result.get("error", "ç”Ÿæˆå¤±è´¥"))

    detail = result.get("detail", {})

    # æ›´æ–°é˜¶æ®µä¿¡æ¯
    updated_phase = {
        **phase,
        "status": "completed",
        "keyPoints": detail.get("key_points", []),
        "resources": [
            {"name": r.get("name", ""), "type": r.get("type", "")}
            for r in detail.get("learning_resources", [])
        ],
        "milestone": (
            detail.get("milestones", [{}])[0].get("goal", "") if detail.get("milestones") else ""
        ),
        "goals": phase.get("goals", []) or detail.get("practice_suggestions", []),
    }

    # æ›´æ–°æ•°æ®åº“
    phases[phase_index] = updated_phase
    await db.update_by_id("study_plans", plan_id, {"phases": phases})

    return {"success": True, "data": {"phaseDetail": updated_phase}}


@router.post("/phase-detail/stream")
async def generate_phase_detail_stream(request: Request):
    """
    ç”Ÿæˆå­¦ä¹ é˜¶æ®µè¯¦æƒ…ï¼ˆæµå¼å“åº”ï¼‰
    
    è¿”å› Server-Sent Events æ ¼å¼ï¼š
    - data: {"type": "progress", "message": "..."} - è¿›åº¦æ›´æ–°
    - data: {"type": "content", "content": "..."} - AI åŸå§‹è¾“å‡ºç‰‡æ®µ
    - data: {"type": "result", "success": true, "phaseDetail": {...}} - æœ€ç»ˆç»“æœ
    - data: {"type": "error", "error": "..."} - é”™è¯¯ä¿¡æ¯
    - data: [DONE] - ç»“æŸæ ‡è®°
    """
    import logging
    logger = logging.getLogger(__name__)
    
    openid = _get_openid_from_request(request)
    db = get_db()

    try:
        body = await request.json()
    except Exception:
        raise HTTPException(status_code=400, detail="è¯·æ±‚ä½“æ ¼å¼é”™è¯¯")

    plan_id = body.get("planId") or body.get("plan_id")
    phase_id = body.get("phaseId") or body.get("phase_id")

    if not plan_id or not phase_id:
        raise HTTPException(status_code=400, detail="ç¼ºå°‘ planId æˆ– phaseId")

    # è·å–è®¡åˆ’
    plan = await db.get_by_id("study_plans", plan_id)
    if not plan:
        raise HTTPException(status_code=404, detail="è®¡åˆ’ä¸å­˜åœ¨")
    
    # å…¼å®¹æ—§ç‰ˆåµŒå¥—æ•°æ®ç»“æ„
    if "data" in plan and isinstance(plan.get("data"), dict) and "openid" not in plan:
        nested_data = plan.get("data")
        plan = {**nested_data, "_id": plan.get("_id")}
    
    if plan.get("openid") != openid:
        raise HTTPException(status_code=403, detail="æ— æƒè®¿é—®è¯¥è®¡åˆ’")

    # æ‰¾åˆ°å¯¹åº”é˜¶æ®µ
    phases = plan.get("phases") or []
    phase = None
    phase_index = -1
    for i, p in enumerate(phases):
        if p.get("id") == phase_id:
            phase = p
            phase_index = i
            break

    if not phase:
        raise HTTPException(status_code=404, detail="é˜¶æ®µä¸å­˜åœ¨")

    async def generate():
        """ä½¿ç”¨ JSON æ¨¡å¼ç”Ÿæˆé˜¶æ®µè¯¦æƒ…ï¼ˆæ›´å¯é ï¼‰"""
        try:
            yield f"data: {json.dumps({'type': 'progress', 'message': 'æ­£åœ¨åˆ†æé˜¶æ®µç›®æ ‡...'})}\n\n"
            
            yield f"data: {json.dumps({'type': 'progress', 'message': 'æ­£åœ¨ç”Ÿæˆé˜¶æ®µè¯¦æƒ…ï¼ˆçº¦éœ€30-60ç§’ï¼‰...'})}\n\n"
            
            # ä½¿ç”¨ JSON æ¨¡å¼è°ƒç”¨ AIï¼ˆéæµå¼ï¼Œä½†æ›´å¯é ï¼‰
            result = await PlanService.generate_phase_detail(
                phase_name=phase.get("name", ""),
                phase_goals=phase.get("goals", []),
                domain=plan.get("domainName") or plan.get("domain", ""),
                duration=phase.get("duration", "1å‘¨"),
            )
            
            if result.get("success") and result.get("detail"):
                detail = result["detail"]
                
                yield f"data: {json.dumps({'type': 'progress', 'message': 'æ­£åœ¨ä¿å­˜é˜¶æ®µè¯¦æƒ…...'})}\n\n"
                
                # æ›´æ–°é˜¶æ®µä¿¡æ¯
                updated_phase = {
                    **phase,
                    "status": "completed",
                    "keyPoints": detail.get("key_points", []),
                    "resources": [
                        {"name": r.get("name", ""), "type": r.get("type", "")}
                        for r in detail.get("learning_resources", [])
                    ],
                    "milestone": (
                        detail.get("milestones", [{}])[0].get("goal", "") if detail.get("milestones") else ""
                    ),
                    "goals": phase.get("goals", []) or detail.get("practice_suggestions", []),
                }
                
                # æ›´æ–°æ•°æ®åº“
                try:
                    phases[phase_index] = updated_phase
                    await db.update_by_id("study_plans", plan_id, {"phases": phases})
                    logger.info(f"[phase-detail/stream] é˜¶æ®µ {phase_id} è¯¦æƒ…å·²ä¿å­˜")
                except Exception as db_err:
                    logger.error(f"[phase-detail/stream] æ•°æ®åº“æ›´æ–°å¤±è´¥: {db_err}")
                
                yield f"data: {json.dumps({'type': 'result', 'success': True, 'phaseDetail': updated_phase})}\n\n"
            else:
                # AI è°ƒç”¨å¤±è´¥ï¼Œè¿”å›åŸºæœ¬é˜¶æ®µä¿¡æ¯
                error_msg = result.get("error", "ç”Ÿæˆå¤±è´¥")
                logger.error(f"[phase-detail/stream] AI ç”Ÿæˆå¤±è´¥: {error_msg}")
                
                fallback_phase = {
                    **phase,
                    "status": "completed",
                    "keyPoints": [],
                    "resources": [],
                    "milestone": "",
                }
                yield f"data: {json.dumps({'type': 'result', 'success': True, 'phaseDetail': fallback_phase, 'warning': error_msg})}\n\n"
                
        except Exception as e:
            logger.error(f"[phase-detail/stream] å¼‚å¸¸: {type(e).__name__}: {str(e)}", exc_info=True)
            # å³ä½¿å‡ºé”™ä¹Ÿè¿”å›åŸºæœ¬ç»“æœï¼Œä¸é˜»å¡æµç¨‹
            fallback_phase = {
                **phase,
                "status": "completed",
                "keyPoints": [],
                "resources": [],
                "milestone": "",
            }
            yield f"data: {json.dumps({'type': 'result', 'success': True, 'phaseDetail': fallback_phase, 'warning': str(e)})}\n\n"
        
        yield "data: [DONE]\n\n"
    
    return StreamingResponse(
        generate(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no",
        },
    )


# ==================== ç›®æ ‡è¾¾æˆç‡ API ====================


@router.get("/achievement")
async def get_achievement_rate(request: Request):
    """
    è·å–ç›®æ ‡è¾¾æˆç‡ï¼ˆæ›¿ä»£äº‘å‡½æ•° getAchievementRateï¼‰
    """
    openid = _get_openid_from_request(request)
    db = get_db()
    plan_repo = PlanRepository(db)

    plan = await plan_repo.get_active_plan(openid)
    if not plan:
        return {"success": True, "data": {"hasActivePlan": False}}

    # ç¡®ä¿ plan_id æ˜¯å­—ç¬¦ä¸²æ ¼å¼
    raw_id = plan.get("_id") or plan.get("id")
    plan_id = str(raw_id) if raw_id else None

    # è®¡ç®—ä»»åŠ¡å®Œæˆç‡ï¼ˆæœ€è¿‘7å¤©ï¼‰
    today_start, _ = _beijing_day_range(0)
    week_start = today_start - timedelta(days=7)

    all_tasks = await db.query(
        "plan_tasks",
        {
            "openid": openid,
            "planId": plan_id,
            "date": {
                "$gte": {"$date": week_start.isoformat()},
                "$lt": {"$date": (today_start + timedelta(days=1)).isoformat()},
            },
        },
        limit=500,
    )

    total_tasks = len(all_tasks)
    completed_tasks = len([t for t in all_tasks if t.get("completed")])
    task_completion_rate = int(round((completed_tasks / total_tasks) * 100)) if total_tasks else 0

    # è®¡ç®—é˜¶æ®µè¿›åº¦ï¼ˆå·²å®Œæˆé˜¶æ®µæ•° / æ€»é˜¶æ®µæ•°ï¼‰
    current_phase = _get_current_phase(plan)
    phases = plan.get("phases") or []
    phase_progress = 0
    if current_phase and phases:
        # phase_index è¡¨ç¤ºå½“å‰åœ¨ç¬¬å‡ é˜¶æ®µï¼ˆä»1å¼€å§‹ï¼‰ï¼Œå·²å®Œæˆçš„æ˜¯ phase_index - 1
        phase_index = current_phase.get("index", 1)
        completed_phases = phase_index - 1
        phase_progress = int(round((completed_phases / len(phases)) * 100))

    # è®¡ç®—å­¦ä¹ æ´»è·ƒåº¦ï¼ˆæœ‰å®Œæˆä»»åŠ¡çš„å¤©æ•° / 7ï¼‰
    # åªç»Ÿè®¡æœ‰ä»»åŠ¡è¢«å®Œæˆçš„å¤©æ•°ï¼Œè€Œä¸æ˜¯æœ‰ä»»åŠ¡åˆ›å»ºçš„å¤©æ•°
    completed_tasks = [t for t in all_tasks if t.get("completed")]
    active_days = len(set(t.get("dateStr") or "" for t in completed_tasks if t.get("dateStr")))
    activity_rate = int(round((active_days / 7) * 100))

    # ç»¼åˆè¾¾æˆç‡ï¼ˆåŠ æƒå¹³å‡ï¼‰
    achievement_rate = int(
        round(task_completion_rate * 0.5 + phase_progress * 0.3 + activity_rate * 0.2)
    )

    # è¾¾æˆç­‰çº§
    if achievement_rate >= 80:
        level = "excellent"
        analysis = "å­¦ä¹ è¿›åº¦éå¸¸æ£’ï¼ä¿æŒè¿™ä¸ªèŠ‚å¥ï¼Œç›®æ ‡æŒ‡æ—¥å¯å¾… ğŸ‰"
    elif achievement_rate >= 60:
        level = "good"
        analysis = "å­¦ä¹ çŠ¶æ€è‰¯å¥½ï¼Œç»§ç»­åŠªåŠ›ï¼Œå¯ä»¥é€‚å½“å¢åŠ æŒ‘æˆ˜ ğŸ’ª"
    elif achievement_rate >= 40:
        level = "warning"
        analysis = "å­¦ä¹ è¿›åº¦ç¨æ…¢ï¼Œå»ºè®®æ¯å¤©å›ºå®šæ—¶é—´å­¦ä¹ ï¼Œå…»æˆä¹ æƒ¯ ğŸ“š"
    else:
        level = "danger"
        analysis = "éœ€è¦è°ƒæ•´å­¦ä¹ è®¡åˆ’ï¼Œå»ºè®®å‡å°‘å•æ¬¡ä»»åŠ¡é‡ï¼Œé™ä½éš¾åº¦ ğŸŒ±"

    # é¢„æµ‹
    remaining_days = _calculate_remaining_days(plan)
    prediction = ""
    if remaining_days and remaining_days > 0:
        if achievement_rate >= 70:
            prediction = "æŒ‰å½“å‰è¿›åº¦ï¼Œé¢„è®¡å¯ä»¥åœ¨æˆªæ­¢æ—¥æœŸå‰å®Œæˆç›®æ ‡"
        else:
            prediction = f"è¿˜æœ‰ {remaining_days} å¤©ï¼Œå»ºè®®å¢åŠ æ¯æ—¥å­¦ä¹ æ—¶é—´ä»¥ç¡®ä¿è¾¾æˆç›®æ ‡"

    # å»ºè®®
    suggestions = []
    if task_completion_rate < 60:
        suggestions.append("å°è¯•å°†å¤§ä»»åŠ¡æ‹†åˆ†æˆå°æ­¥éª¤ï¼Œæ›´å®¹æ˜“å®Œæˆ")
    if activity_rate < 70:
        suggestions.append("è®¾ç½®å›ºå®šçš„å­¦ä¹ æ—¶é—´ï¼Œä¿æŒæ¯æ—¥æ‰“å¡")
    if phase_progress < 50 and remaining_days and remaining_days < 30:
        suggestions.append("æ—¶é—´ç´§è¿«ï¼Œå»ºè®®é›†ä¸­ç²¾åŠ›æ”»å…‹å½“å‰é˜¶æ®µé‡ç‚¹")

    return {
        "success": True,
        "data": {
            "hasActivePlan": True,
            "achievementRate": achievement_rate,
            "achievementLevel": level,
            "achievementAnalysis": analysis,
            "achievementPrediction": prediction,
            "taskCompletionRate": task_completion_rate,
            "phaseProgress": phase_progress,
            "activityRate": activity_rate,
            "remainingDays": remaining_days,
            "suggestions": suggestions,
        },
    }


@router.get("/dashboard")
async def get_dashboard(request: Request):
    """
    å­¦ä¹ â€œå˜å¼ºä»ªè¡¨ç›˜â€æ•°æ®ï¼š
    - çŸ¥è¯†ç‚¹æŒæ¡åº¦ï¼ˆåŸºäºé”™é¢˜ tags/æŒæ¡çŠ¶æ€ï¼‰
    - ç¨³å®šæ€§ï¼ˆæœ€è¿‘3æ¡é”™é¢˜æ˜¯å¦å·²æŒæ¡çš„æ¯”ä¾‹ï¼Œè¿‘ä¼¼å£å¾„ï¼‰
    - æŠ•å…¥æ—¶é—´ï¼ˆfocus_recordsï¼‰
    - å®Œæˆç‡ï¼ˆplan_tasksï¼‰
    """
    openid = _get_openid_from_request(request)
    db = get_db()
    plan_repo = PlanRepository(db)

    plan = await plan_repo.get_active_plan(openid)
    if not plan:
        return {"success": True, "data": {"hasActivePlan": False}}

    raw_id = plan.get("_id") or plan.get("id")
    plan_id = str(raw_id) if raw_id else None
    if not plan_id:
        raise HTTPException(status_code=500, detail="å­¦ä¹ è®¡åˆ’ç¼ºå°‘ _id")

    today_start, _ = _beijing_day_range(0)
    week_start = today_start - timedelta(days=7)
    tomorrow_start, _ = _beijing_day_range(1)

    def _datestr_from_date_field(date_val: Any) -> Optional[str]:
        try:
            dt = None
            if isinstance(date_val, dict) and "$date" in date_val:
                dt = datetime.fromisoformat(str(date_val["$date"]).replace("Z", "+00:00"))
            elif isinstance(date_val, str):
                dt = datetime.fromisoformat(date_val.replace("Z", "+00:00"))
            elif isinstance(date_val, datetime):
                dt = date_val
            if not dt:
                return None
            if not dt.tzinfo:
                dt = dt.replace(tzinfo=timezone.utc)
            bj = dt.astimezone(timezone.utc) + timedelta(hours=8)
            return bj.date().isoformat()
        except Exception:
            return None

    # ====== ä»»åŠ¡å®Œæˆç‡ï¼ˆè¿‘7å¤©ï¼‰======
    tasks = await db.query(
        "plan_tasks",
        {
            "openid": openid,
            "planId": plan_id,
            "date": {"$gte": {"$date": week_start.isoformat()}, "$lt": {"$date": tomorrow_start.isoformat()}},
        },
        limit=2000,
        order_by="date",
        order_type="asc",
    )
    daily_task = {}
    for t in tasks:
        d = t.get("dateStr") or _datestr_from_date_field(t.get("date"))
        if not d:
            continue
        if d not in daily_task:
            daily_task[d] = {"dateStr": d, "total": 0, "completed": 0, "minutesPlanned": 0}
        daily_task[d]["total"] += 1
        daily_task[d]["minutesPlanned"] += int(t.get("duration") or 0)
        if t.get("completed"):
            daily_task[d]["completed"] += 1
    daily_task_list = sorted(daily_task.values(), key=lambda x: x["dateStr"])
    for x in daily_task_list:
        x["completionRate"] = int(round((x["completed"] / x["total"]) * 100)) if x["total"] else 0

    today_key = _beijing_date_str(0)
    today_row = daily_task.get(today_key, {"dateStr": today_key, "total": 0, "completed": 0, "minutesPlanned": 0, "completionRate": 0})
    total_7 = sum(x["total"] for x in daily_task_list)
    completed_7 = sum(x["completed"] for x in daily_task_list)
    completion_7 = int(round((completed_7 / total_7) * 100)) if total_7 else 0

    # ====== æŠ•å…¥æ—¶é—´ï¼ˆfocus_records è¿‘7å¤©ï¼‰======
    focus_records = await db.query(
        "focus_records",
        {"openid": openid, "date": {"$gte": {"$date": week_start.isoformat()}, "$lt": {"$date": tomorrow_start.isoformat()}}},
        limit=2000,
        order_by="date",
        order_type="asc",
    )
    daily_focus = {}
    for r in focus_records:
        d = _datestr_from_date_field(r.get("date"))
        if not d:
            continue
        if d not in daily_focus:
            daily_focus[d] = {"dateStr": d, "minutes": 0, "count": 0}
        daily_focus[d]["minutes"] += int(r.get("duration") or 0)
        daily_focus[d]["count"] += 1
    daily_focus_list = sorted(daily_focus.values(), key=lambda x: x["dateStr"])
    today_focus = daily_focus.get(today_key, {"minutes": 0, "count": 0})
    week_focus_minutes = sum(x["minutes"] for x in daily_focus_list)

    # ====== çŸ¥è¯†ç‚¹æŒæ¡åº¦ï¼ˆé”™é¢˜ tags è¿‘ä¼¼ï¼‰======
    mistakes = await db.query(
        "mistakes",
        {"openid": openid},
        limit=1000,
        order_by="createdAt",
        order_type="desc",
    )
    by_tag: Dict[str, List[Dict[str, Any]]] = {}
    for m in mistakes:
        tags = m.get("tags") or []
        if not isinstance(tags, list) or not tags:
            # fallbackï¼šç”¨ category ä½œä¸ºå¼±æ ‡ç­¾
            cat = str(m.get("category") or "").strip()
            tags = [cat] if cat else []
        for t in tags:
            tag = str(t).strip()
            if not tag:
                continue
            by_tag.setdefault(tag, []).append(m)

    tag_rows = []
    for tag, ms in by_tag.items():
        total = len(ms)
        mastered = len([x for x in ms if x.get("mastered")])
        last3 = ms[:3]
        stability = (len([x for x in last3 if x.get("mastered")]) / 3.0) if len(last3) >= 3 else (mastered / total if total else 0.0)
        tag_rows.append(
            {
                "tag": tag,
                "total": total,
                "mastered": mastered,
                "mastery": round(mastered / total, 3) if total else 0.0,
                "stability": round(stability, 3),
            }
        )
    # é€‰ï¼šå…ˆçœ‹æœªæŒæ¡å¤šçš„ï¼Œå†çœ‹æ€»é‡
    tag_rows.sort(key=lambda x: (-(x["total"] - x["mastered"]), -x["total"]))
    top_tags = tag_rows[:8]
    overall_total = sum(x["total"] for x in tag_rows)
    overall_mastered = sum(x["mastered"] for x in tag_rows)
    overall_mastery = round(overall_mastered / overall_total, 3) if overall_total else 0.0

    return {
        "success": True,
        "data": {
            "hasActivePlan": True,
            "planId": plan_id,
            "dateStr": today_key,
            "tasks": {
                "today": today_row,
                "last7CompletionRate": completion_7,
                "daily": daily_task_list,
            },
            "focus": {
                "todayMinutes": int(today_focus.get("minutes") or 0),
                "todayCount": int(today_focus.get("count") or 0),
                "last7Minutes": int(week_focus_minutes),
                "daily": daily_focus_list,
            },
            "knowledge": {
                "overallMastery": overall_mastery,
                "top": top_tags,
            },
        },
    }


# ==================== æ˜æ—¥ä»»åŠ¡ API ====================


@router.post("/tomorrow-tasks")
async def generate_tomorrow_tasks(request: Request):
    """
    ç”Ÿæˆæ˜æ—¥ä»»åŠ¡ï¼ˆæ›¿ä»£äº‘å‡½æ•° generateTomorrowTasksï¼‰
    """
    openid = _get_openid_from_request(request)
    db = get_db()
    plan_repo = PlanRepository(db)

    plan = await plan_repo.get_active_plan(openid)
    if not plan:
        raise HTTPException(status_code=404, detail="æ²¡æœ‰æ´»è·ƒçš„å­¦ä¹ è®¡åˆ’")

    # ç¡®ä¿ plan_id æ˜¯å­—ç¬¦ä¸²æ ¼å¼
    raw_id = plan.get("_id") or plan.get("id")
    plan_id = str(raw_id) if raw_id else None
    tomorrow_str = _beijing_date_str(1)
    tomorrow_start, tomorrow_end = _beijing_day_range(1)

    # æ£€æŸ¥æ˜¯å¦å·²æœ‰æ˜æ—¥ä»»åŠ¡
    existing = await db.query(
        "plan_tasks",
        {"openid": openid, "planId": plan_id, "dateStr": tomorrow_str},
        limit=100,
    )
    if existing:
        return {
            "success": True,
            "data": {
                "tasks": existing,
                "isNew": False,
                "message": "æ˜æ—¥ä»»åŠ¡å·²å­˜åœ¨",
            },
        }

    # è·å–å­¦ä¹ ä¸Šä¸‹æ–‡
    today_str = _beijing_date_str(0)
    today_tasks = await db.query(
        "plan_tasks",
        {"openid": openid, "planId": plan_id, "dateStr": today_str},
        limit=100,
    )
    today_completed = len([t for t in today_tasks if t.get("completed")])
    today_total = len(today_tasks)
    completion_rate = int(round((today_completed / today_total) * 100)) if today_total else 0

    # ========= åŠ¨æ€é‡æ’ï¼šæŠŠä»Šæ—¥æœªå®Œæˆä»»åŠ¡è‡ªåŠ¨æ¬åˆ°æ˜å¤© =========
    total_minutes = max(20, int(float(plan.get("dailyHours") or 2) * 60))
    carry_max_minutes = int(total_minutes * 0.6)
    carry_max_count = 3

    pending_today = []
    for t in today_tasks:
        if t.get("completed"):
            continue
        if t.get("carriedToDateStr") == tomorrow_str:
            continue
        pending_today.append(t)

    priority_rank = {"high": 0, "medium": 1, "low": 2}
    pending_today.sort(key=lambda x: (priority_rank.get(x.get("priority", "medium"), 1), int(x.get("order") or 0)))

    carry_tasks = []
    carry_minutes = 0
    for t in pending_today:
        if len(carry_tasks) >= carry_max_count:
            break
        dur = int(t.get("duration") or 30)
        if carry_minutes + dur > carry_max_minutes:
            continue
        carry_tasks.append(t)
        carry_minutes += dur

    # ç»„è£… learning_contextï¼ˆé”™é¢˜ + ç»­åš + ä¸ªæ€§åŒ–åå¥½ + èŠ‚å¥ï¼‰
    mistakes = await db.query(
        "mistakes",
        {"openid": openid, "mastered": False},
        limit=5,
        order_by="createdAt",
        order_type="desc",
    )
    simplified_mistakes = []
    for m in mistakes:
        simplified_mistakes.append(
            {
                "id": m.get("_id") or m.get("id"),
                "topic": (m.get("category") or "") if m.get("category") else None,
                "question": m.get("question") or "",
                "tags": m.get("tags") or [],
            }
        )
    personalization = plan.get("personalization") if isinstance(plan, dict) else {}
    learning_context = {
        "carryover": {"uncompletedTitles": [t.get("title") for t in pending_today[:5] if t.get("title")]},
        "mistakes": simplified_mistakes,
        "preferences": personalization if isinstance(personalization, dict) else {},
        "pace": {
            "carryoverMinutes": carry_minutes,
            "missedDays": 1 if (completion_rate == 0 and today_total > 0) else 0,
            "highCompletionStreak": 1 if (completion_rate >= 95 and today_total > 0) else 0,
        },
    }

    # è·å–å½“å‰é˜¶æ®µ
    current_phase = _get_current_phase(plan)

    # ç”Ÿæˆä»»åŠ¡ï¼ˆå…ˆå†™å…¥æ¬è¿ä»»åŠ¡ï¼Œå†ç”¨å‰©ä½™æ—¶é—´ç”Ÿæˆæ–°ä»»åŠ¡ï¼‰
    domain = plan.get("domainName") or plan.get("domain", "")

    saved_tasks: List[Dict[str, Any]] = []
    now = datetime.now(timezone.utc).isoformat()
    order_cursor = 0

    if carry_tasks:
        for t in carry_tasks:
            doc = {
                "planId": plan_id,
                "openid": openid,
                "phaseId": (current_phase or {}).get("id") or t.get("phaseId"),
                "title": t.get("title") or "è¡¥åšä»»åŠ¡",
                "description": t.get("description") or "",
                "duration": int(t.get("duration", 30)),
                "priority": t.get("priority", "medium"),
                "type": t.get("type", "review"),
                "completed": False,
                "order": order_cursor,
                "date": {"$date": tomorrow_start.isoformat()},
                "dateStr": tomorrow_str,
                "createdAt": {"$date": now},
                "generatedBy": "carryover",
                "carriedFromDateStr": today_str,
                "originTaskId": str(t.get("_id") or t.get("id") or ""),
            }
            new_id = await db.add("plan_tasks", doc)
            doc["_id"] = new_id
            saved_tasks.append(doc)
            order_cursor += 1

            origin_id = t.get("_id") or t.get("id")
            if origin_id:
                await db.update_by_id("plan_tasks", str(origin_id), {"carriedToDateStr": tomorrow_str, "carriedAt": {"$date": now}})

    remaining_minutes = max(0, total_minutes - carry_minutes)
    adjusted_daily_hours = max(0.3, remaining_minutes / 60.0) if remaining_minutes else 0.3

    tasks = await PlanService.generate_daily_tasks(
        domain=domain,
        daily_hours=adjusted_daily_hours,
        current_phase=current_phase,
        learning_history={"avgCompletionRate": completion_rate},
        today_stats={"completionRate": completion_rate},
        learning_context=learning_context,
    )

    for i, t in enumerate(tasks):
        doc = {
            "planId": plan_id,
            "openid": openid,
            "phaseId": (current_phase or {}).get("id"),
            "title": t.get("title", f"ä»»åŠ¡{i+1}"),
            "description": t.get("description", ""),
            "duration": int(t.get("duration", 30)),
            "priority": t.get("priority", "medium"),
            "type": t.get("type", "learn"),
            "completed": False,
            "order": order_cursor + i,
            "date": {"$date": tomorrow_start.isoformat()},
            "dateStr": tomorrow_str,
            "createdAt": {"$date": now},
            "generatedBy": "fastapi_ai",
        }
        new_id = await db.add("plan_tasks", doc)
        doc["_id"] = new_id
        saved_tasks.append(doc)

    # åˆ†æä¿¡æ¯
    analysis = {
        "avgCompletionRate": completion_rate,
        "adjustment": (
            "æ ¹æ®æ‚¨çš„å®Œæˆç‡ï¼Œå·²é€‚å½“è°ƒæ•´ä»»åŠ¡éš¾åº¦"
            if completion_rate < 70
            else "ç»§ç»­ä¿æŒå½“å‰å­¦ä¹ èŠ‚å¥"
        ),
    }

    return {
        "success": True,
        "data": {
            "tasks": saved_tasks,
            "analysis": analysis,
            "isNew": True,
            "message": "æ˜æ—¥ä»»åŠ¡å·²ç”Ÿæˆ",
        },
    }


@router.post("/tomorrow-tasks/stream")
async def generate_tomorrow_tasks_stream(request: Request):
    """
    ç”Ÿæˆæ˜æ—¥ä»»åŠ¡ï¼ˆæµå¼å“åº”ï¼‰
    
    è¿”å› Server-Sent Events æ ¼å¼ï¼š
    - data: {"type": "progress", "message": "..."} - è¿›åº¦æ›´æ–°
    - data: {"type": "content", "content": "..."} - AI åŸå§‹è¾“å‡ºç‰‡æ®µ
    - data: {"type": "result", "success": true, "tasks": [...]} - æœ€ç»ˆç»“æœ
    - data: {"type": "error", "error": "..."} - é”™è¯¯ä¿¡æ¯
    - data: [DONE] - ç»“æŸæ ‡è®°
    """
    import logging
    logger = logging.getLogger(__name__)
    
    openid = _get_openid_from_request(request)
    db = get_db()
    plan_repo = PlanRepository(db)

    plan = await plan_repo.get_active_plan(openid)
    if not plan:
        raise HTTPException(status_code=404, detail="æ²¡æœ‰æ´»è·ƒçš„å­¦ä¹ è®¡åˆ’")

    # ç¡®ä¿ plan_id æ˜¯å­—ç¬¦ä¸²æ ¼å¼
    raw_id = plan.get("_id") or plan.get("id")
    plan_id = str(raw_id) if raw_id else None
    tomorrow_str = _beijing_date_str(1)
    tomorrow_start, tomorrow_end = _beijing_day_range(1)

    # æ£€æŸ¥æ˜¯å¦å·²æœ‰æ˜æ—¥ä»»åŠ¡
    existing = await db.query(
        "plan_tasks",
        {"openid": openid, "planId": plan_id, "dateStr": tomorrow_str},
        limit=100,
    )
    if existing:
        # å·²æœ‰ä»»åŠ¡ï¼Œç›´æ¥è¿”å›éæµå¼ç»“æœ
        return {
            "success": True,
            "data": {
                "tasks": existing,
                "isNew": False,
                "message": "æ˜æ—¥ä»»åŠ¡å·²å­˜åœ¨",
            },
        }

    # è·å–å­¦ä¹ ä¸Šä¸‹æ–‡
    today_str = _beijing_date_str(0)
    today_tasks = await db.query(
        "plan_tasks",
        {"openid": openid, "planId": plan_id, "dateStr": today_str},
        limit=100,
    )
    today_completed = len([t for t in today_tasks if t.get("completed")])
    today_total = len(today_tasks)
    completion_rate = int(round((today_completed / today_total) * 100)) if today_total else 0

    # ========= åŠ¨æ€é‡æ’ï¼šæŠŠä»Šæ—¥æœªå®Œæˆä»»åŠ¡è‡ªåŠ¨æ¬åˆ°æ˜å¤©ï¼ˆæµå¼ç‰ˆä¹Ÿä¸€è‡´ï¼‰ =========
    total_minutes = max(20, int(float(plan.get("dailyHours") or 2) * 60))
    carry_max_minutes = int(total_minutes * 0.6)
    carry_max_count = 3

    pending_today = []
    for t in today_tasks:
        if t.get("completed"):
            continue
        if t.get("carriedToDateStr") == tomorrow_str:
            continue
        pending_today.append(t)

    priority_rank = {"high": 0, "medium": 1, "low": 2}
    pending_today.sort(key=lambda x: (priority_rank.get(x.get("priority", "medium"), 1), int(x.get("order") or 0)))

    carry_tasks = []
    carry_minutes = 0
    for t in pending_today:
        if len(carry_tasks) >= carry_max_count:
            break
        dur = int(t.get("duration") or 30)
        if carry_minutes + dur > carry_max_minutes:
            continue
        carry_tasks.append(t)
        carry_minutes += dur

    # learning_contextï¼ˆé”™é¢˜ + ç»­åš + ä¸ªæ€§åŒ–åå¥½ + èŠ‚å¥ï¼‰
    mistakes = await db.query(
        "mistakes",
        {"openid": openid, "mastered": False},
        limit=5,
        order_by="createdAt",
        order_type="desc",
    )
    simplified_mistakes = []
    for m in mistakes:
        simplified_mistakes.append(
            {
                "id": m.get("_id") or m.get("id"),
                "topic": (m.get("category") or "") if m.get("category") else None,
                "question": m.get("question") or "",
                "tags": m.get("tags") or [],
            }
        )
    personalization = plan.get("personalization") if isinstance(plan, dict) else {}
    learning_context = {
        "carryover": {"uncompletedTitles": [t.get("title") for t in pending_today[:5] if t.get("title")]},
        "mistakes": simplified_mistakes,
        "preferences": personalization if isinstance(personalization, dict) else {},
        "pace": {
            "carryoverMinutes": carry_minutes,
            "missedDays": 1 if (completion_rate == 0 and today_total > 0) else 0,
            "highCompletionStreak": 1 if (completion_rate >= 95 and today_total > 0) else 0,
        },
    }

    # è·å–å½“å‰é˜¶æ®µï¼ˆæµå¼ç‰ˆéœ€è¦åœ¨æ¬è¿ä»»åŠ¡å†™å…¥å‰å¯ç”¨ï¼‰
    current_phase = _get_current_phase(plan)

    carry_saved_tasks: List[Dict[str, Any]] = []
    order_offset = 0
    now = datetime.now(timezone.utc).isoformat()
    if carry_tasks:
        for t in carry_tasks:
            doc = {
                "planId": plan_id,
                "openid": openid,
                "phaseId": (current_phase or {}).get("id") or t.get("phaseId"),
                "title": t.get("title") or "è¡¥åšä»»åŠ¡",
                "description": t.get("description") or "",
                "duration": int(t.get("duration", 30)),
                "priority": t.get("priority", "medium"),
                "type": t.get("type", "review"),
                "completed": False,
                "order": order_offset,
                "date": {"$date": tomorrow_start.isoformat()},
                "dateStr": tomorrow_str,
                "createdAt": {"$date": now},
                "generatedBy": "carryover",
                "carriedFromDateStr": today_str,
                "originTaskId": str(t.get("_id") or t.get("id") or ""),
            }
            new_id = await db.add("plan_tasks", doc)
            doc["_id"] = new_id
            carry_saved_tasks.append(doc)
            order_offset += 1

            origin_id = t.get("_id") or t.get("id")
            if origin_id:
                await db.update_by_id("plan_tasks", str(origin_id), {"carriedToDateStr": tomorrow_str, "carriedAt": {"$date": now}})

    remaining_minutes = max(0, total_minutes - carry_minutes)
    adjusted_daily_hours = max(0.3, remaining_minutes / 60.0) if remaining_minutes else 0.3

    # ç”Ÿæˆä»»åŠ¡å‚æ•°
    domain = plan.get("domainName") or plan.get("domain", "")
    daily_hours = adjusted_daily_hours

    async def generate():
        full_content = ""
        
        try:
            yield f"data: {json.dumps({'type': 'progress', 'message': 'æ­£åœ¨åˆ†æå­¦ä¹ è¿›åº¦...'})}\n\n"
            
            yield f"data: {json.dumps({'type': 'progress', 'message': 'æ­£åœ¨ç”Ÿæˆæ˜æ—¥ä»»åŠ¡...'})}\n\n"
            
            # æµå¼è°ƒç”¨ AI
            async for chunk in PlanService.generate_daily_tasks_stream(
                domain=domain,
                daily_hours=daily_hours,
                current_phase=current_phase,
                learning_history={"avgCompletionRate": completion_rate},
                today_stats={"completionRate": completion_rate},
                learning_context=learning_context,
            ):
                full_content += chunk
                yield f"data: {json.dumps({'type': 'content', 'content': chunk})}\n\n"
            
            yield f"data: {json.dumps({'type': 'progress', 'message': 'æ­£åœ¨è§£æä»»åŠ¡åˆ—è¡¨...'})}\n\n"
            
            # è§£æ JSON æ•°ç»„
            json_match = re.search(r'\[[\s\S]*\]', full_content)
            if json_match:
                try:
                    tasks = json.loads(json_match.group())
                    tasks = PlanService._validate_tasks(tasks, daily_hours)
                    
                    yield f"data: {json.dumps({'type': 'progress', 'message': 'æ­£åœ¨ä¿å­˜ä»»åŠ¡...'})}\n\n"
                    
                    # ä¿å­˜ä»»åŠ¡
                    saved_tasks: List[Dict[str, Any]] = list(carry_saved_tasks)
                    now = datetime.now(timezone.utc).isoformat()
                    for i, t in enumerate(tasks):
                        doc = {
                            "planId": plan_id,
                            "openid": openid,
                            "phaseId": (current_phase or {}).get("id"),
                            "title": t.get("title", f"ä»»åŠ¡{i+1}"),
                            "description": t.get("description", ""),
                            "duration": int(t.get("duration", 30)),
                            "priority": t.get("priority", "medium"),
                            "type": t.get("type", "learn"),
                            "completed": False,
                            "order": order_offset + i,
                            "date": {"$date": tomorrow_start.isoformat()},
                            "dateStr": tomorrow_str,
                            "createdAt": {"$date": now},
                            "generatedBy": "fastapi_ai_stream",
                        }
                        new_id = await db.add("plan_tasks", doc)
                        doc["_id"] = new_id
                        saved_tasks.append(doc)
                    
                    # åˆ†æä¿¡æ¯
                    analysis = {
                        "avgCompletionRate": completion_rate,
                        "adjustment": (
                            "æ ¹æ®æ‚¨çš„å®Œæˆç‡ï¼Œå·²é€‚å½“è°ƒæ•´ä»»åŠ¡éš¾åº¦"
                            if completion_rate < 70
                            else "ç»§ç»­ä¿æŒå½“å‰å­¦ä¹ èŠ‚å¥"
                        ),
                    }
                    
                    yield f"data: {json.dumps({'type': 'result', 'success': True, 'tasks': saved_tasks, 'analysis': analysis, 'isNew': True})}\n\n"
                except json.JSONDecodeError as je:
                    logger.error(f"[tomorrow-tasks/stream] JSON è§£æå¤±è´¥: {je}")
                    yield f"data: {json.dumps({'type': 'error', 'error': f'JSONè§£æå¤±è´¥: {str(je)}'})}\n\n"
            else:
                logger.error("[tomorrow-tasks/stream] AI å“åº”ä¸­æœªæ‰¾åˆ° JSON")
                yield f"data: {json.dumps({'type': 'error', 'error': 'ç”Ÿæˆæ ¼å¼é”™è¯¯ï¼Œæœªæ‰¾åˆ°æœ‰æ•ˆJSON'})}\n\n"
                
        except Exception as e:
            logger.error(f"[tomorrow-tasks/stream] å¼‚å¸¸: {type(e).__name__}: {str(e)}", exc_info=True)
            yield f"data: {json.dumps({'type': 'error', 'error': str(e)})}\n\n"
        
        yield "data: [DONE]\n\n"
    
    return StreamingResponse(
        generate(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no",
        },
    )


# ==================== å…¶ä»– API ====================


@router.post("/generate-tasks", response_model=GenerateTasksResponse)
async def generate_daily_tasks(request: GenerateTasksRequest):
    """
    ç”Ÿæˆæ¯æ—¥å­¦ä¹ ä»»åŠ¡ï¼ˆä¸ä¿å­˜ï¼Œä»…è¿”å›ï¼‰
    """
    try:
        tasks = await PlanService.generate_daily_tasks(
            domain=request.domain,
            daily_hours=request.daily_hours,
            current_phase=request.current_phase,
            learning_history=request.learning_history,
            today_stats=request.today_stats,
        )
        return GenerateTasksResponse(success=True, tasks=tasks)
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/analyze-mistake", response_model=AnalyzeMistakeResponse)
async def analyze_mistake(request: AnalyzeMistakeRequest):
    """
    é”™é¢˜åˆ†æ
    """
    try:
        analysis = await AIService.analyze_mistake(
            question=request.question,
            user_answer=request.user_answer,
            correct_answer=request.correct_answer,
            subject=request.subject,
            image_url=request.image_url,
        )
        return AnalyzeMistakeResponse(success=True, analysis=analysis)
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/analyze-mistake/stream")
async def analyze_mistake_stream(request: AnalyzeMistakeRequest):
    """
    é”™é¢˜åˆ†æï¼ˆæµå¼å“åº” SSEï¼‰

    è¿”å›æ ¼å¼ï¼š
    - data: {"content": "..."}  (å¤šæ¬¡)
    - data: [DONE]
    """
    try:
        async def generate():
            try:
                async for chunk in AIService.analyze_mistake_text_stream(
                    question=request.question,
                    user_answer=request.user_answer,
                    correct_answer=request.correct_answer,
                    subject=request.subject,
                    image_url=request.image_url,
                ):
                    yield f"data: {json.dumps({'content': chunk})}\n\n"
                yield "data: [DONE]\n\n"
            except Exception as e:
                yield f"data: {json.dumps({'error': str(e)})}\n\n"

        return StreamingResponse(
            generate(),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "X-Accel-Buffering": "no",
            },
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))