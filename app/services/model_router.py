"""
æ™ºèƒ½æ¨¡å‹è·¯ç”±å™¨æ¨¡å—
æ ¹æ®æ¶ˆæ¯ç±»å‹å’Œç”¨æˆ·é…ç½®é€‰æ‹©åˆé€‚çš„ AI æ¨¡å‹

Requirements: 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 9.5
"""

import logging
from typing import Optional, Dict, Any, List, AsyncGenerator
from enum import Enum

from ..config import settings
from .model_config_service import ModelConfigService
from .ai_service import AIService
from .model_dispatchers import ModelDispatcher
from ..utils.error_logger import (
    log_model_error,
    log_config_error,
    set_request_context,
    generate_request_id,
)

logger = logging.getLogger(__name__)


class MessageType(Enum):
    """æ¶ˆæ¯ç±»å‹æšä¸¾"""
    TEXT = "text"
    IMAGE = "image"
    VOICE = "voice"
    MULTIMODAL = "multimodal"  # æ–‡æœ¬+å›¾ç‰‡


class ModelRouter:
    """
    æ™ºèƒ½æ¨¡å‹è·¯ç”±å™¨
    
    æ ¹æ®æ¶ˆæ¯ç±»å‹å’Œç”¨æˆ·é…ç½®é€‰æ‹©åˆé€‚çš„æ¨¡å‹ï¼š
    - æ–‡æœ¬æ¶ˆæ¯ â†’ æ–‡æœ¬æ¨¡å‹
    - å›¾ç‰‡æ¶ˆæ¯ â†’ è§†è§‰/å¤šæ¨¡æ€æ¨¡å‹
    - è¯­éŸ³æ¶ˆæ¯ â†’ è¯­éŸ³æ¨¡å‹ï¼ˆæˆ–é™çº§åˆ° ASR + æ–‡æœ¬æ¨¡å‹ï¼‰
    - æ–‡æœ¬+å›¾ç‰‡ â†’ å¤šæ¨¡æ€æ¨¡å‹
    """
    
    @classmethod
    def detect_message_type(cls, message: Dict[str, Any]) -> MessageType:
        """
        æ£€æµ‹æ¶ˆæ¯ç±»å‹
        
        Args:
            message: æ¶ˆæ¯å­—å…¸ï¼Œå¯èƒ½åŒ…å« text, image_url, image_base64, voice_url, voice_text
            
        Returns:
            MessageType æšä¸¾å€¼
        """
        has_text = bool(message.get("text"))
        has_image = bool(message.get("image_url") or message.get("image_base64"))
        has_voice = bool(message.get("voice_url") or message.get("voice_text"))
        
        if has_image and has_text:
            return MessageType.MULTIMODAL
        elif has_image:
            return MessageType.IMAGE
        elif has_voice:
            return MessageType.VOICE
        else:
            return MessageType.TEXT
    
    @classmethod
    async def route_and_call(
        cls,
        openid: str,
        message: Dict[str, Any],
        history: List[Dict] = None,
        context: Optional[Dict] = None,
        stream: bool = True,
        user_memory: Optional[Dict] = None,
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """
        è·¯ç”±å¹¶è°ƒç”¨åˆé€‚çš„æ¨¡å‹
        
        Args:
            openid: ç”¨æˆ· openid
            message: å¤šæ¨¡æ€æ¶ˆæ¯
            history: å¯¹è¯å†å²
            context: ä¸Šä¸‹æ–‡ï¼ˆå¦‚æ–‡æ¡£ä¼´è¯»çš„æ–‡æ¡£å†…å®¹ï¼‰
            stream: æ˜¯å¦æµå¼å“åº”
            user_memory: ç”¨æˆ·è®°å¿†/ç”»åƒ
            
        Yields:
            æµå¼å“åº”äº‹ä»¶å­—å…¸
        """
        history = history or []
        
        # è®¾ç½®è¯·æ±‚ä¸Šä¸‹æ–‡ç”¨äºé”™è¯¯æ—¥å¿—
        request_id = generate_request_id()
        set_request_context(request_id=request_id, openid=openid)
        
        # ========== è¯¦ç»†æ—¥å¿—ï¼šæ¥æ”¶åˆ°çš„æ¶ˆæ¯ ==========
        logger.info("=" * 60)
        logger.info(f"[ModelRouter] ğŸš€ æ–°è¯·æ±‚å¼€å§‹")
        logger.info(f"[ModelRouter] request_id: {request_id}")
        logger.info(f"[ModelRouter] openid: {openid[:8]}***")
        logger.info(f"[ModelRouter] stream: {stream}")
        logger.info(f"[ModelRouter] history_count: {len(history)}")
        logger.info(f"[ModelRouter] has_context: {context is not None}")
        logger.info(f"[ModelRouter] has_user_memory: {user_memory is not None}")
        
        # æ‰“å°æ¶ˆæ¯å†…å®¹æ‘˜è¦
        text_content = message.get("text", "")
        logger.info(f"[ModelRouter] ğŸ“ æ¶ˆæ¯å†…å®¹:")
        logger.info(f"  - text: {text_content[:100]}{'...' if len(text_content) > 100 else ''}" if text_content else "  - text: (æ— )")
        logger.info(f"  - image_url: {'æœ‰' if message.get('image_url') else 'æ— '}")
        logger.info(f"  - image_base64: {'æœ‰' if message.get('image_base64') else 'æ— '}")
        logger.info(f"  - voice_url: {'æœ‰' if message.get('voice_url') else 'æ— '}")
        logger.info(f"  - voice_text: {'æœ‰' if message.get('voice_text') else 'æ— '}")
        
        # æ£€æµ‹æ¶ˆæ¯ç±»å‹
        msg_type = cls.detect_message_type(message)
        logger.info(f"[ModelRouter] ğŸ” æ£€æµ‹åˆ°æ¶ˆæ¯ç±»å‹: {msg_type.value}")
        
        # æ ¹æ®æ¶ˆæ¯ç±»å‹è·å–æ¨¡å‹é…ç½®
        if msg_type == MessageType.TEXT:
            model_type = "text"
        elif msg_type in (MessageType.IMAGE, MessageType.MULTIMODAL):
            model_type = "multimodal"
        elif msg_type == MessageType.VOICE:
            # è¯­éŸ³æ¶ˆæ¯ï¼šå¦‚æœæœ‰ voice_textï¼ˆå·²è½¬æ–‡æœ¬ï¼‰ï¼Œä½¿ç”¨æ–‡æœ¬æ¨¡å‹
            # å¦åˆ™éœ€è¦è¯­éŸ³æ¨¡å‹
            if message.get("voice_text"):
                model_type = "text"
                logger.info(f"[ModelRouter] è¯­éŸ³å·²è½¬æ–‡æœ¬ï¼Œä½¿ç”¨æ–‡æœ¬æ¨¡å‹")
            else:
                model_type = "voice"
        else:
            model_type = "text"
        
        logger.info(f"[ModelRouter] ğŸ“‹ éœ€è¦çš„æ¨¡å‹ç±»å‹: {model_type}")
        
        # è·å–ç”¨æˆ·é…ç½®çš„æ¨¡å‹
        model_config = await ModelConfigService.get_model_for_type(openid, model_type)
        
        # ========== è¯¦ç»†æ—¥å¿—ï¼šé€‰æ‹©çš„æ¨¡å‹ ==========
        logger.info(f"[ModelRouter] âœ… æ¨¡å‹é€‰æ‹©ç»“æœ:")
        logger.info(f"  - platform: {model_config['platform']}")
        logger.info(f"  - model: {model_config['model']}")
        logger.info(f"  - base_url: {model_config['base_url'][:50]}...")
        logger.info(f"  - is_user_config: {model_config.get('is_user_config', False)}")
        logger.info(f"  - api_key: {'å·²é…ç½®' if model_config.get('api_key') else 'âŒ æœªé…ç½®'}")
        logger.info("=" * 60)
        
        # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
        messages = cls._build_messages(message, history, context, user_memory, msg_type)
        logger.info(f"[ModelRouter] ğŸ“¨ æ„å»ºæ¶ˆæ¯åˆ—è¡¨å®Œæˆï¼Œå…± {len(messages)} æ¡æ¶ˆæ¯")
        
        # è°ƒç”¨æ¨¡å‹ï¼ˆå¸¦é™çº§ï¼‰
        fallback_config = cls._get_fallback_config()
        
        # æå–è¯­éŸ³ URLï¼ˆç”¨äº Gemini éŸ³é¢‘ç†è§£ï¼‰
        voice_url = message.get("voice_url") if msg_type == MessageType.VOICE else None
        
        try:
            async for event in cls._call_with_fallback(
                primary_config=model_config,
                fallback_config=fallback_config,
                messages=messages,
                stream=stream,
                msg_type=msg_type,
                openid=openid,
                voice_url=voice_url,
            ):
                yield event
        except Exception as e:
            log_model_error(
                message=f"æ¨¡å‹è°ƒç”¨æœ€ç»ˆå¤±è´¥: {type(e).__name__}: {e}",
                platform=model_config.get("platform", "unknown"),
                model=model_config.get("model", "unknown"),
                openid=openid,
                exception=e,
            )
            yield {
                "type": "error",
                "error": str(e),
            }
    
    @classmethod
    async def _call_with_fallback(
        cls,
        primary_config: Dict[str, Any],
        fallback_config: Dict[str, Any],
        messages: List[Dict],
        stream: bool,
        msg_type: MessageType,
        openid: str = None,
        voice_url: str = None,
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """
        å¸¦é™çº§çš„æ¨¡å‹è°ƒç”¨
        
        Args:
            primary_config: ä¸»æ¨¡å‹é…ç½®
            fallback_config: é™çº§æ¨¡å‹é…ç½®
            messages: æ¶ˆæ¯åˆ—è¡¨
            stream: æ˜¯å¦æµå¼
            msg_type: æ¶ˆæ¯ç±»å‹
            openid: ç”¨æˆ·æ ‡è¯†ï¼ˆç”¨äºé”™è¯¯æ—¥å¿—ï¼‰
            voice_url: è¯­éŸ³æ–‡ä»¶URLï¼ˆç”¨äºéŸ³é¢‘ç†è§£ï¼‰
            
        Yields:
            æµå¼å“åº”äº‹ä»¶
        """
        used_fallback = False
        fallback_reason = None
        
        # æ£€æŸ¥ä¸»æ¨¡å‹é…ç½®æ˜¯å¦æœ‰æ•ˆ
        if not primary_config.get("api_key"):
            logger.warning(f"[ModelRouter] âš ï¸ ä¸»æ¨¡å‹ API Key æœªé…ç½®")
            logger.warning(f"  - platform: {primary_config.get('platform')}")
            logger.warning(f"  - model: {primary_config.get('model')}")
            logger.info(f"[ModelRouter] ğŸ”„ åˆ‡æ¢åˆ°é™çº§æ¨¡å‹: {fallback_config['platform']}/{fallback_config['model']}")
            
            log_config_error(
                message="ä¸»æ¨¡å‹ API Key æœªé…ç½®ï¼Œä½¿ç”¨é™çº§æ¨¡å‹",
                openid=openid,
                config_type=msg_type.value,
            )
            used_fallback = True
            fallback_reason = "API Key æœªé…ç½®"
            primary_config = fallback_config
        
        try:
            # å°è¯•è°ƒç”¨ä¸»æ¨¡å‹
            async for chunk in cls._call_model(
                config=primary_config,
                messages=messages,
                stream=stream,
                msg_type=msg_type,
                openid=openid,
                voice_url=voice_url,
            ):
                if used_fallback and chunk.get("type") == "text":
                    # ç¬¬ä¸€ä¸ªæ–‡æœ¬å—æ—¶æ ‡è®°ä½¿ç”¨äº†é™çº§
                    chunk["fallback_used"] = True
                    chunk["fallback_reason"] = fallback_reason
                    used_fallback = False  # åªæ ‡è®°ä¸€æ¬¡
                yield chunk
                
        except Exception as e:
            logger.error(f"[ModelRouter] âŒ ä¸»æ¨¡å‹è°ƒç”¨å¤±è´¥: {type(e).__name__}: {e}")
            
            log_model_error(
                message=f"ä¸»æ¨¡å‹è°ƒç”¨å¤±è´¥: {type(e).__name__}: {e}",
                platform=primary_config.get("platform", "unknown"),
                model=primary_config.get("model", "unknown"),
                openid=openid,
                exception=e,
            )
            
            # å¦‚æœä¸»æ¨¡å‹å°±æ˜¯é™çº§æ¨¡å‹ï¼Œç›´æ¥æŠ›å‡ºé”™è¯¯
            if primary_config.get("platform") == fallback_config.get("platform") and \
               primary_config.get("model") == fallback_config.get("model"):
                logger.error(f"[ModelRouter] âŒ é™çº§æ¨¡å‹ä¹Ÿå¤±è´¥ï¼Œæ— æ³•ç»§ç»­")
                raise
            
            # å°è¯•é™çº§æ¨¡å‹
            logger.info(f"[ModelRouter] ğŸ”„ å°è¯•é™çº§åˆ°: {fallback_config['platform']}/{fallback_config['model']}")
            
            yield {
                "type": "fallback_notice",
                "message": f"æ‚¨é…ç½®çš„æ¨¡å‹æš‚æ—¶ä¸å¯ç”¨ï¼Œå·²åˆ‡æ¢åˆ°é»˜è®¤æ¨¡å‹",
                "fallback_used": True,
                "fallback_reason": str(e),
            }
            
            async for chunk in cls._call_model(
                config=fallback_config,
                messages=messages,
                stream=stream,
                msg_type=msg_type,
                openid=openid,
                voice_url=voice_url,
            ):
                yield chunk
    
    @classmethod
    async def _call_model(
        cls,
        config: Dict[str, Any],
        messages: List[Dict],
        stream: bool,
        msg_type: MessageType,
        openid: str = None,
        voice_url: str = None,
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """
        è°ƒç”¨æ¨¡å‹ APIï¼ˆä½¿ç”¨åˆ†å‘å™¨æ¨¡å¼ï¼‰
        
        Args:
            config: æ¨¡å‹é…ç½®
            messages: æ¶ˆæ¯åˆ—è¡¨
            stream: æ˜¯å¦æµå¼
            msg_type: æ¶ˆæ¯ç±»å‹
            openid: ç”¨æˆ·æ ‡è¯†ï¼ˆç”¨äºé”™è¯¯æ—¥å¿—ï¼‰
            voice_url: è¯­éŸ³æ–‡ä»¶URLï¼ˆç”¨äºéŸ³é¢‘ç†è§£ï¼‰
            
        Yields:
            æµå¼å“åº”äº‹ä»¶
        """
        model = config["model"]
        platform = config.get("platform", "unknown")
        base_url = config["base_url"]
        
        # ========== è¯¦ç»†æ—¥å¿—ï¼šAPI è°ƒç”¨ ==========
        logger.info(f"[ModelRouter] ğŸŒ å¼€å§‹è°ƒç”¨æ¨¡å‹ API")
        logger.info(f"  - platform: {platform}")
        logger.info(f"  - model: {model}")
        logger.info(f"  - base_url: {base_url}")
        logger.info(f"  - stream: {stream}")
        logger.info(f"  - messages_count: {len(messages)}")
        logger.info(f"  - has_voice_url: {bool(voice_url)}")
        
        # è·å–åˆ†å‘å™¨
        has_voice = msg_type == MessageType.VOICE and voice_url
        dispatcher = ModelDispatcher.get_dispatcher(platform, model, has_voice)
        
        logger.info(f"[ModelRouter] ğŸ“¤ ä½¿ç”¨åˆ†å‘å™¨: {type(dispatcher).__name__}")
        
        # è°ƒç”¨åˆ†å‘å™¨
        async for event in dispatcher.call(
            config=config,
            messages=messages,
            stream=stream,
            openid=openid,
            voice_url=voice_url,
        ):
            yield event
    
    # æ³¨æ„ï¼šæµå¼å’Œéæµå¼è¯·æ±‚é€»è¾‘å·²ç§»è‡³ model_dispatchers.py ä¸­çš„å„åˆ†å‘å™¨ç±»
    # OpenAICompatibleDispatcher, GeminiDispatcher, GeminiAudioDispatcher ç­‰
    
    @classmethod
    def _build_messages(
        cls,
        message: Dict[str, Any],
        history: List[Dict],
        context: Optional[Dict],
        user_memory: Optional[Dict],
        msg_type: MessageType,
    ) -> List[Dict]:
        """
        æ„å»ºå‘é€ç»™æ¨¡å‹çš„æ¶ˆæ¯åˆ—è¡¨
        """
        messages = []
        
        # ç³»ç»Ÿæç¤ºè¯
        system_prompt = AIService.COACH_SYSTEM_PROMPT
        
        # æ·»åŠ ç”¨æˆ·è®°å¿†
        if user_memory:
            memory_info = AIService._format_user_memory(user_memory)
            if memory_info:
                system_prompt += f"\n\nã€ç”¨æˆ·æ¡£æ¡ˆã€‘\n{memory_info}"
        
        # æ·»åŠ æ–‡æ¡£ä¸Šä¸‹æ–‡
        if context:
            doc_title = context.get("title", "")
            doc_content = context.get("content", "")
            if doc_content:
                system_prompt += f"\n\nã€å½“å‰æ–‡æ¡£ã€‘\næ ‡é¢˜ï¼š{doc_title}\nå†…å®¹ï¼š\n{doc_content[:3000]}"
        
        messages.append({"role": "system", "content": system_prompt})
        
        # æ·»åŠ å¯¹è¯å†å²
        for msg in history:
            messages.append({
                "role": msg.get("role", "user"),
                "content": msg.get("content", ""),
            })
        
        # æ·»åŠ å½“å‰æ¶ˆæ¯
        current_content = cls._build_current_message_content(message, msg_type)
        messages.append({"role": "user", "content": current_content})
        
        return messages
    
    @classmethod
    def _build_current_message_content(
        cls,
        message: Dict[str, Any],
        msg_type: MessageType,
    ) -> Any:
        """
        æ„å»ºå½“å‰æ¶ˆæ¯å†…å®¹
        
        å¯¹äºå¤šæ¨¡æ€æ¶ˆæ¯ï¼Œè¿”å›åŒ…å«æ–‡æœ¬å’Œå›¾ç‰‡çš„åˆ—è¡¨
        å¯¹äºçº¯æ–‡æœ¬æ¶ˆæ¯ï¼Œè¿”å›å­—ç¬¦ä¸²
        """
        if msg_type == MessageType.TEXT:
            return message.get("text", "")
        
        elif msg_type == MessageType.VOICE:
            # è¯­éŸ³å·²è½¬æ–‡æœ¬
            return message.get("voice_text", message.get("text", ""))
        
        elif msg_type in (MessageType.IMAGE, MessageType.MULTIMODAL):
            # å¤šæ¨¡æ€æ¶ˆæ¯
            content = []
            
            # æ·»åŠ æ–‡æœ¬
            text = message.get("text", "")
            if text:
                content.append({"type": "text", "text": text})
            elif msg_type == MessageType.IMAGE:
                # çº¯å›¾ç‰‡æ¶ˆæ¯ï¼Œæ·»åŠ é»˜è®¤æç¤º
                content.append({"type": "text", "text": "è¯·åˆ†æè¿™å¼ å›¾ç‰‡"})
            
            # æ·»åŠ å›¾ç‰‡
            image_url = message.get("image_url")
            image_base64 = message.get("image_base64")
            
            if image_url:
                content.append({
                    "type": "image_url",
                    "image_url": {"url": image_url}
                })
            elif image_base64:
                # Base64 æ ¼å¼
                content.append({
                    "type": "image_url",
                    "image_url": {"url": f"data:image/jpeg;base64,{image_base64}"}
                })
            
            return content
        
        return message.get("text", "")
    
    @classmethod
    def _get_fallback_config(cls) -> Dict[str, Any]:
        """
        è·å–é™çº§æ¨¡å‹é…ç½®ï¼ˆç³»ç»Ÿé»˜è®¤ï¼‰
        """
        return {
            "platform": "deepseek",
            "model": "deepseek-chat",
            "base_url": "https://api.deepseek.com/v1",
            "api_key": settings.DEEPSEEK_API_KEY,
            "is_fallback": True,
        }
