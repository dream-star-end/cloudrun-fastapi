"""
æ™ºèƒ½æ¨¡å‹è·¯ç”±å™¨æ¨¡å—
æ ¹æ®æ¶ˆæ¯ç±»å‹å’Œç”¨æˆ·é…ç½®é€‰æ‹©åˆé€‚çš„ AI æ¨¡å‹

Requirements: 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 9.5
"""

import httpx
import json
import logging
from typing import Optional, Dict, Any, List, AsyncGenerator
from enum import Enum

from ..config import settings, get_http_client_kwargs
from .model_config_service import ModelConfigService
from .ai_service import AIService
from ..utils.error_logger import (
    log_model_error,
    log_config_error,
    log_stream_error,
    set_request_context,
    generate_request_id,
)

logger = logging.getLogger(__name__)


class MessageType(Enum):
    """æ¶ˆæ¯ç±»å‹æšä¸¾"""
    TEXT = "text"
    IMAGE = "image"
    VOICE = "voice"
    MULTIMODAL = "multimodal"  # æ–‡æœ¬+å›¾ç‰‡


class ModelRouter:
    """
    æ™ºèƒ½æ¨¡å‹è·¯ç”±å™¨
    
    æ ¹æ®æ¶ˆæ¯ç±»å‹å’Œç”¨æˆ·é…ç½®é€‰æ‹©åˆé€‚çš„æ¨¡å‹ï¼š
    - æ–‡æœ¬æ¶ˆæ¯ â†’ æ–‡æœ¬æ¨¡å‹
    - å›¾ç‰‡æ¶ˆæ¯ â†’ è§†è§‰/å¤šæ¨¡æ€æ¨¡å‹
    - è¯­éŸ³æ¶ˆæ¯ â†’ è¯­éŸ³æ¨¡å‹ï¼ˆæˆ–é™çº§åˆ° ASR + æ–‡æœ¬æ¨¡å‹ï¼‰
    - æ–‡æœ¬+å›¾ç‰‡ â†’ å¤šæ¨¡æ€æ¨¡å‹
    """
    
    @classmethod
    def detect_message_type(cls, message: Dict[str, Any]) -> MessageType:
        """
        æ£€æµ‹æ¶ˆæ¯ç±»å‹
        
        Args:
            message: æ¶ˆæ¯å­—å…¸ï¼Œå¯èƒ½åŒ…å« text, image_url, image_base64, voice_url, voice_text
            
        Returns:
            MessageType æšä¸¾å€¼
        """
        has_text = bool(message.get("text"))
        has_image = bool(message.get("image_url") or message.get("image_base64"))
        has_voice = bool(message.get("voice_url") or message.get("voice_text"))
        
        if has_image and has_text:
            return MessageType.MULTIMODAL
        elif has_image:
            return MessageType.IMAGE
        elif has_voice:
            return MessageType.VOICE
        else:
            return MessageType.TEXT
    
    @classmethod
    async def route_and_call(
        cls,
        openid: str,
        message: Dict[str, Any],
        history: List[Dict] = None,
        context: Optional[Dict] = None,
        stream: bool = True,
        user_memory: Optional[Dict] = None,
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """
        è·¯ç”±å¹¶è°ƒç”¨åˆé€‚çš„æ¨¡å‹
        
        Args:
            openid: ç”¨æˆ· openid
            message: å¤šæ¨¡æ€æ¶ˆæ¯
            history: å¯¹è¯å†å²
            context: ä¸Šä¸‹æ–‡ï¼ˆå¦‚æ–‡æ¡£ä¼´è¯»çš„æ–‡æ¡£å†…å®¹ï¼‰
            stream: æ˜¯å¦æµå¼å“åº”
            user_memory: ç”¨æˆ·è®°å¿†/ç”»åƒ
            
        Yields:
            æµå¼å“åº”äº‹ä»¶å­—å…¸
        """
        history = history or []
        
        # è®¾ç½®è¯·æ±‚ä¸Šä¸‹æ–‡ç”¨äºé”™è¯¯æ—¥å¿—
        request_id = generate_request_id()
        set_request_context(request_id=request_id, openid=openid)
        
        # ========== è¯¦ç»†æ—¥å¿—ï¼šæ¥æ”¶åˆ°çš„æ¶ˆæ¯ ==========
        logger.info("=" * 60)
        logger.info(f"[ModelRouter] ğŸš€ æ–°è¯·æ±‚å¼€å§‹")
        logger.info(f"[ModelRouter] request_id: {request_id}")
        logger.info(f"[ModelRouter] openid: {openid[:8]}***")
        logger.info(f"[ModelRouter] stream: {stream}")
        logger.info(f"[ModelRouter] history_count: {len(history)}")
        logger.info(f"[ModelRouter] has_context: {context is not None}")
        logger.info(f"[ModelRouter] has_user_memory: {user_memory is not None}")
        
        # æ‰“å°æ¶ˆæ¯å†…å®¹æ‘˜è¦
        text_content = message.get("text", "")
        logger.info(f"[ModelRouter] ğŸ“ æ¶ˆæ¯å†…å®¹:")
        logger.info(f"  - text: {text_content[:100]}{'...' if len(text_content) > 100 else ''}" if text_content else "  - text: (æ— )")
        logger.info(f"  - image_url: {'æœ‰' if message.get('image_url') else 'æ— '}")
        logger.info(f"  - image_base64: {'æœ‰' if message.get('image_base64') else 'æ— '}")
        logger.info(f"  - voice_url: {'æœ‰' if message.get('voice_url') else 'æ— '}")
        logger.info(f"  - voice_text: {'æœ‰' if message.get('voice_text') else 'æ— '}")
        
        # æ£€æµ‹æ¶ˆæ¯ç±»å‹
        msg_type = cls.detect_message_type(message)
        logger.info(f"[ModelRouter] ğŸ” æ£€æµ‹åˆ°æ¶ˆæ¯ç±»å‹: {msg_type.value}")
        
        # æ ¹æ®æ¶ˆæ¯ç±»å‹è·å–æ¨¡å‹é…ç½®
        if msg_type == MessageType.TEXT:
            model_type = "text"
        elif msg_type in (MessageType.IMAGE, MessageType.MULTIMODAL):
            model_type = "multimodal"
        elif msg_type == MessageType.VOICE:
            # è¯­éŸ³æ¶ˆæ¯ï¼šå¦‚æœæœ‰ voice_textï¼ˆå·²è½¬æ–‡æœ¬ï¼‰ï¼Œä½¿ç”¨æ–‡æœ¬æ¨¡å‹
            # å¦åˆ™éœ€è¦è¯­éŸ³æ¨¡å‹
            if message.get("voice_text"):
                model_type = "text"
                logger.info(f"[ModelRouter] è¯­éŸ³å·²è½¬æ–‡æœ¬ï¼Œä½¿ç”¨æ–‡æœ¬æ¨¡å‹")
            else:
                model_type = "voice"
        else:
            model_type = "text"
        
        logger.info(f"[ModelRouter] ğŸ“‹ éœ€è¦çš„æ¨¡å‹ç±»å‹: {model_type}")
        
        # è·å–ç”¨æˆ·é…ç½®çš„æ¨¡å‹
        model_config = await ModelConfigService.get_model_for_type(openid, model_type)
        
        # ========== è¯¦ç»†æ—¥å¿—ï¼šé€‰æ‹©çš„æ¨¡å‹ ==========
        logger.info(f"[ModelRouter] âœ… æ¨¡å‹é€‰æ‹©ç»“æœ:")
        logger.info(f"  - platform: {model_config['platform']}")
        logger.info(f"  - model: {model_config['model']}")
        logger.info(f"  - base_url: {model_config['base_url'][:50]}...")
        logger.info(f"  - is_user_config: {model_config.get('is_user_config', False)}")
        logger.info(f"  - api_key: {'å·²é…ç½®' if model_config.get('api_key') else 'âŒ æœªé…ç½®'}")
        logger.info("=" * 60)
        
        # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
        messages = cls._build_messages(message, history, context, user_memory, msg_type)
        logger.info(f"[ModelRouter] ğŸ“¨ æ„å»ºæ¶ˆæ¯åˆ—è¡¨å®Œæˆï¼Œå…± {len(messages)} æ¡æ¶ˆæ¯")
        
        # è°ƒç”¨æ¨¡å‹ï¼ˆå¸¦é™çº§ï¼‰
        fallback_config = cls._get_fallback_config()
        
        try:
            async for event in cls._call_with_fallback(
                primary_config=model_config,
                fallback_config=fallback_config,
                messages=messages,
                stream=stream,
                msg_type=msg_type,
                openid=openid,
            ):
                yield event
        except Exception as e:
            log_model_error(
                message=f"æ¨¡å‹è°ƒç”¨æœ€ç»ˆå¤±è´¥: {type(e).__name__}: {e}",
                platform=model_config.get("platform", "unknown"),
                model=model_config.get("model", "unknown"),
                openid=openid,
                exception=e,
            )
            yield {
                "type": "error",
                "error": str(e),
            }
    
    @classmethod
    async def _call_with_fallback(
        cls,
        primary_config: Dict[str, Any],
        fallback_config: Dict[str, Any],
        messages: List[Dict],
        stream: bool,
        msg_type: MessageType,
        openid: str = None,
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """
        å¸¦é™çº§çš„æ¨¡å‹è°ƒç”¨
        
        Args:
            primary_config: ä¸»æ¨¡å‹é…ç½®
            fallback_config: é™çº§æ¨¡å‹é…ç½®
            messages: æ¶ˆæ¯åˆ—è¡¨
            stream: æ˜¯å¦æµå¼
            msg_type: æ¶ˆæ¯ç±»å‹
            openid: ç”¨æˆ·æ ‡è¯†ï¼ˆç”¨äºé”™è¯¯æ—¥å¿—ï¼‰
            
        Yields:
            æµå¼å“åº”äº‹ä»¶
        """
        used_fallback = False
        fallback_reason = None
        
        # æ£€æŸ¥ä¸»æ¨¡å‹é…ç½®æ˜¯å¦æœ‰æ•ˆ
        if not primary_config.get("api_key"):
            logger.warning(f"[ModelRouter] âš ï¸ ä¸»æ¨¡å‹ API Key æœªé…ç½®")
            logger.warning(f"  - platform: {primary_config.get('platform')}")
            logger.warning(f"  - model: {primary_config.get('model')}")
            logger.info(f"[ModelRouter] ğŸ”„ åˆ‡æ¢åˆ°é™çº§æ¨¡å‹: {fallback_config['platform']}/{fallback_config['model']}")
            
            log_config_error(
                message="ä¸»æ¨¡å‹ API Key æœªé…ç½®ï¼Œä½¿ç”¨é™çº§æ¨¡å‹",
                openid=openid,
                config_type=msg_type.value,
            )
            used_fallback = True
            fallback_reason = "API Key æœªé…ç½®"
            primary_config = fallback_config
        
        try:
            # å°è¯•è°ƒç”¨ä¸»æ¨¡å‹
            async for chunk in cls._call_model(
                config=primary_config,
                messages=messages,
                stream=stream,
                msg_type=msg_type,
                openid=openid,
            ):
                if used_fallback and chunk.get("type") == "text":
                    # ç¬¬ä¸€ä¸ªæ–‡æœ¬å—æ—¶æ ‡è®°ä½¿ç”¨äº†é™çº§
                    chunk["fallback_used"] = True
                    chunk["fallback_reason"] = fallback_reason
                    used_fallback = False  # åªæ ‡è®°ä¸€æ¬¡
                yield chunk
                
        except Exception as e:
            logger.error(f"[ModelRouter] âŒ ä¸»æ¨¡å‹è°ƒç”¨å¤±è´¥: {type(e).__name__}: {e}")
            
            log_model_error(
                message=f"ä¸»æ¨¡å‹è°ƒç”¨å¤±è´¥: {type(e).__name__}: {e}",
                platform=primary_config.get("platform", "unknown"),
                model=primary_config.get("model", "unknown"),
                openid=openid,
                exception=e,
            )
            
            # å¦‚æœä¸»æ¨¡å‹å°±æ˜¯é™çº§æ¨¡å‹ï¼Œç›´æ¥æŠ›å‡ºé”™è¯¯
            if primary_config.get("platform") == fallback_config.get("platform") and \
               primary_config.get("model") == fallback_config.get("model"):
                logger.error(f"[ModelRouter] âŒ é™çº§æ¨¡å‹ä¹Ÿå¤±è´¥ï¼Œæ— æ³•ç»§ç»­")
                raise
            
            # å°è¯•é™çº§æ¨¡å‹
            logger.info(f"[ModelRouter] ğŸ”„ å°è¯•é™çº§åˆ°: {fallback_config['platform']}/{fallback_config['model']}")
            
            yield {
                "type": "fallback_notice",
                "message": f"æ‚¨é…ç½®çš„æ¨¡å‹æš‚æ—¶ä¸å¯ç”¨ï¼Œå·²åˆ‡æ¢åˆ°é»˜è®¤æ¨¡å‹",
                "fallback_used": True,
                "fallback_reason": str(e),
            }
            
            async for chunk in cls._call_model(
                config=fallback_config,
                messages=messages,
                stream=stream,
                msg_type=msg_type,
                openid=openid,
            ):
                yield chunk
    
    @classmethod
    async def _call_model(
        cls,
        config: Dict[str, Any],
        messages: List[Dict],
        stream: bool,
        msg_type: MessageType,
        openid: str = None,
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """
        è°ƒç”¨æ¨¡å‹ API
        
        Args:
            config: æ¨¡å‹é…ç½®
            messages: æ¶ˆæ¯åˆ—è¡¨
            stream: æ˜¯å¦æµå¼
            msg_type: æ¶ˆæ¯ç±»å‹
            openid: ç”¨æˆ·æ ‡è¯†ï¼ˆç”¨äºé”™è¯¯æ—¥å¿—ï¼‰
            
        Yields:
            æµå¼å“åº”äº‹ä»¶
        """
        base_url = config["base_url"]
        api_key = config["api_key"]
        model = config["model"]
        platform = config.get("platform", "unknown")
        
        # ========== è¯¦ç»†æ—¥å¿—ï¼šAPI è°ƒç”¨ ==========
        logger.info(f"[ModelRouter] ğŸŒ å¼€å§‹è°ƒç”¨æ¨¡å‹ API")
        logger.info(f"  - platform: {platform}")
        logger.info(f"  - model: {model}")
        logger.info(f"  - base_url: {base_url}")
        logger.info(f"  - stream: {stream}")
        logger.info(f"  - messages_count: {len(messages)}")
        
        request_body = {
            "model": model,
            "messages": messages,
            "temperature": 0.7,
            "max_tokens": 4000,
            "stream": stream,
        }
        
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}",
        }
        
        # æ—¥å¿—ä¸­è„±æ•æ˜¾ç¤º API Key
        logger.info(f"[ModelRouter] ğŸ“¤ å‘é€è¯·æ±‚åˆ°: {base_url}/chat/completions")
        logger.info(f"  - Authorization: Bearer {api_key[:8]}***" if api_key else "  - Authorization: Bearer (empty)")
        
        if stream:
            async for event in cls._stream_request(
                base_url, headers, request_body, 
                platform=platform, model=model, openid=openid
            ):
                yield event
        else:
            result = await cls._non_stream_request(
                base_url, headers, request_body,
                platform=platform, model=model, openid=openid
            )
            yield result
    
    @classmethod
    async def _stream_request(
        cls,
        base_url: str,
        headers: Dict[str, str],
        request_body: Dict[str, Any],
        platform: str = "unknown",
        model: str = "unknown",
        openid: str = None,
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """
        æµå¼è¯·æ±‚ï¼ˆå¸¦ä¸­æ–­å¤„ç†å’Œéƒ¨åˆ†å†…å®¹ä¿ç•™ï¼‰
        
        Requirements: 9.4
        """
        partial_content_length = 0
        chunk_count = 0
        
        try:
            async with httpx.AsyncClient(**get_http_client_kwargs(120.0)) as client:
                logger.info(f"[ModelRouter] ğŸ”— å»ºç«‹æµå¼è¿æ¥...")
                
                async with client.stream(
                    "POST",
                    f"{base_url}/chat/completions",
                    headers=headers,
                    json=request_body,
                ) as response:
                    logger.info(f"[ModelRouter] ğŸ“¥ æ”¶åˆ°å“åº”: status={response.status_code}")
                    
                    if response.status_code != 200:
                        error_text = ""
                        async for chunk in response.aiter_text():
                            error_text += chunk
                            if len(error_text) > 500:
                                break
                        
                        logger.error(f"[ModelRouter] âŒ API é”™è¯¯: status={response.status_code}")
                        logger.error(f"[ModelRouter] é”™è¯¯å†…å®¹: {error_text[:200]}")
                        
                        log_model_error(
                            message=f"æ¨¡å‹ API é”™è¯¯",
                            platform=platform,
                            model=model,
                            openid=openid,
                            status_code=response.status_code,
                            response_body=error_text,
                        )
                        raise ValueError(f"æ¨¡å‹ API é”™è¯¯ ({response.status_code})")
                    
                    logger.info(f"[ModelRouter] âœ… å¼€å§‹æ¥æ”¶æµå¼æ•°æ®...")
                    
                    async for line in response.aiter_lines():
                        if line.startswith("data: "):
                            data_str = line[6:]
                            if data_str == "[DONE]":
                                logger.info(f"[ModelRouter] ğŸ æµå¼å“åº”å®Œæˆ: å…± {chunk_count} ä¸ªæ•°æ®å—, {partial_content_length} å­—ç¬¦")
                                yield {"type": "done"}
                                break
                            
                            try:
                                data = json.loads(data_str)
                                if data.get("choices") and data["choices"][0].get("delta"):
                                    content = data["choices"][0]["delta"].get("content", "")
                                    if content:
                                        chunk_count += 1
                                        partial_content_length += len(content)
                                        
                                        # æ¯ 10 ä¸ªå—æ‰“å°ä¸€æ¬¡è¿›åº¦
                                        if chunk_count % 10 == 0:
                                            logger.debug(f"[ModelRouter] ğŸ“Š è¿›åº¦: {chunk_count} å—, {partial_content_length} å­—ç¬¦")
                                        
                                        yield {"type": "text", "content": content}
                            except json.JSONDecodeError:
                                continue
                                
        except httpx.ReadTimeout as e:
            # æµå¼è¯»å–è¶…æ—¶
            logger.error(f"[ModelRouter] â° æµå¼å“åº”è¶…æ—¶: å·²æ¥æ”¶ {partial_content_length} å­—ç¬¦")
            log_stream_error(
                message=f"æµå¼å“åº”è¶…æ—¶: {e}",
                openid=openid,
                partial_content_length=partial_content_length,
                exception=e,
            )
            # å¦‚æœå·²æœ‰éƒ¨åˆ†å†…å®¹ï¼Œå‘é€ä¸­æ–­é€šçŸ¥è€Œä¸æ˜¯æŠ›å‡ºé”™è¯¯
            if partial_content_length > 0:
                yield {
                    "type": "stream_interrupted",
                    "message": "å“åº”è¶…æ—¶ï¼Œå·²æ˜¾ç¤ºéƒ¨åˆ†å†…å®¹",
                    "partial_content_length": partial_content_length,
                }
                yield {"type": "done"}
            else:
                raise
                
        except httpx.ReadError as e:
            # æµå¼è¯»å–é”™è¯¯ï¼ˆç½‘ç»œä¸­æ–­ç­‰ï¼‰
            logger.error(f"[ModelRouter] ğŸ”Œ æµå¼å“åº”ä¸­æ–­: å·²æ¥æ”¶ {partial_content_length} å­—ç¬¦")
            log_stream_error(
                message=f"æµå¼å“åº”ä¸­æ–­: {e}",
                openid=openid,
                partial_content_length=partial_content_length,
                exception=e,
            )
            # å¦‚æœå·²æœ‰éƒ¨åˆ†å†…å®¹ï¼Œå‘é€ä¸­æ–­é€šçŸ¥
            if partial_content_length > 0:
                yield {
                    "type": "stream_interrupted",
                    "message": "è¿æ¥ä¸­æ–­ï¼Œå·²æ˜¾ç¤ºéƒ¨åˆ†å†…å®¹",
                    "partial_content_length": partial_content_length,
                }
                yield {"type": "done"}
            else:
                raise
                
        except Exception as e:
            # å…¶ä»–å¼‚å¸¸
            logger.error(f"[ModelRouter] âŒ æµå¼å“åº”å¼‚å¸¸: {type(e).__name__}: {e}")
            if partial_content_length > 0:
                log_stream_error(
                    message=f"æµå¼å“åº”å¼‚å¸¸: {type(e).__name__}: {e}",
                    openid=openid,
                    partial_content_length=partial_content_length,
                    exception=e,
                )
                yield {
                    "type": "stream_interrupted",
                    "message": "å“åº”å¼‚å¸¸ï¼Œå·²æ˜¾ç¤ºéƒ¨åˆ†å†…å®¹",
                    "partial_content_length": partial_content_length,
                }
                yield {"type": "done"}
            else:
                raise
    
    @classmethod
    async def _non_stream_request(
        cls,
        base_url: str,
        headers: Dict[str, str],
        request_body: Dict[str, Any],
        platform: str = "unknown",
        model: str = "unknown",
        openid: str = None,
    ) -> Dict[str, Any]:
        """
        éæµå¼è¯·æ±‚
        """
        async with httpx.AsyncClient(**get_http_client_kwargs(120.0)) as client:
            response = await client.post(
                f"{base_url}/chat/completions",
                headers=headers,
                json=request_body,
            )
            
            if response.status_code != 200:
                error_text = response.text[:500] if response.text else "æ— å“åº”å†…å®¹"
                log_model_error(
                    message=f"æ¨¡å‹ API é”™è¯¯",
                    platform=platform,
                    model=model,
                    openid=openid,
                    status_code=response.status_code,
                    response_body=error_text,
                )
                raise ValueError(f"æ¨¡å‹ API é”™è¯¯ ({response.status_code})")
            
            data = response.json()
            
            if data.get("choices") and data["choices"][0].get("message"):
                content = data["choices"][0]["message"]["content"]
                return {"type": "text", "content": content}
            
            raise ValueError("æ¨¡å‹è¿”å›æ ¼å¼é”™è¯¯")
    
    @classmethod
    def _build_messages(
        cls,
        message: Dict[str, Any],
        history: List[Dict],
        context: Optional[Dict],
        user_memory: Optional[Dict],
        msg_type: MessageType,
    ) -> List[Dict]:
        """
        æ„å»ºå‘é€ç»™æ¨¡å‹çš„æ¶ˆæ¯åˆ—è¡¨
        """
        messages = []
        
        # ç³»ç»Ÿæç¤ºè¯
        system_prompt = AIService.COACH_SYSTEM_PROMPT
        
        # æ·»åŠ ç”¨æˆ·è®°å¿†
        if user_memory:
            memory_info = AIService._format_user_memory(user_memory)
            if memory_info:
                system_prompt += f"\n\nã€ç”¨æˆ·æ¡£æ¡ˆã€‘\n{memory_info}"
        
        # æ·»åŠ æ–‡æ¡£ä¸Šä¸‹æ–‡
        if context:
            doc_title = context.get("title", "")
            doc_content = context.get("content", "")
            if doc_content:
                system_prompt += f"\n\nã€å½“å‰æ–‡æ¡£ã€‘\næ ‡é¢˜ï¼š{doc_title}\nå†…å®¹ï¼š\n{doc_content[:3000]}"
        
        messages.append({"role": "system", "content": system_prompt})
        
        # æ·»åŠ å¯¹è¯å†å²
        for msg in history:
            messages.append({
                "role": msg.get("role", "user"),
                "content": msg.get("content", ""),
            })
        
        # æ·»åŠ å½“å‰æ¶ˆæ¯
        current_content = cls._build_current_message_content(message, msg_type)
        messages.append({"role": "user", "content": current_content})
        
        return messages
    
    @classmethod
    def _build_current_message_content(
        cls,
        message: Dict[str, Any],
        msg_type: MessageType,
    ) -> Any:
        """
        æ„å»ºå½“å‰æ¶ˆæ¯å†…å®¹
        
        å¯¹äºå¤šæ¨¡æ€æ¶ˆæ¯ï¼Œè¿”å›åŒ…å«æ–‡æœ¬å’Œå›¾ç‰‡çš„åˆ—è¡¨
        å¯¹äºçº¯æ–‡æœ¬æ¶ˆæ¯ï¼Œè¿”å›å­—ç¬¦ä¸²
        """
        if msg_type == MessageType.TEXT:
            return message.get("text", "")
        
        elif msg_type == MessageType.VOICE:
            # è¯­éŸ³å·²è½¬æ–‡æœ¬
            return message.get("voice_text", message.get("text", ""))
        
        elif msg_type in (MessageType.IMAGE, MessageType.MULTIMODAL):
            # å¤šæ¨¡æ€æ¶ˆæ¯
            content = []
            
            # æ·»åŠ æ–‡æœ¬
            text = message.get("text", "")
            if text:
                content.append({"type": "text", "text": text})
            elif msg_type == MessageType.IMAGE:
                # çº¯å›¾ç‰‡æ¶ˆæ¯ï¼Œæ·»åŠ é»˜è®¤æç¤º
                content.append({"type": "text", "text": "è¯·åˆ†æè¿™å¼ å›¾ç‰‡"})
            
            # æ·»åŠ å›¾ç‰‡
            image_url = message.get("image_url")
            image_base64 = message.get("image_base64")
            
            if image_url:
                content.append({
                    "type": "image_url",
                    "image_url": {"url": image_url}
                })
            elif image_base64:
                # Base64 æ ¼å¼
                content.append({
                    "type": "image_url",
                    "image_url": {"url": f"data:image/jpeg;base64,{image_base64}"}
                })
            
            return content
        
        return message.get("text", "")
    
    @classmethod
    def _get_fallback_config(cls) -> Dict[str, Any]:
        """
        è·å–é™çº§æ¨¡å‹é…ç½®ï¼ˆç³»ç»Ÿé»˜è®¤ï¼‰
        """
        return {
            "platform": "deepseek",
            "model": "deepseek-chat",
            "base_url": "https://api.deepseek.com/v1",
            "api_key": settings.DEEPSEEK_API_KEY,
            "is_fallback": True,
        }
