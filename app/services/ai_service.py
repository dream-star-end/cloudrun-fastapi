"""
AI æœåŠ¡æ¨¡å—
æ”¯æŒå¤šç§ AI æ¨¡å‹è°ƒç”¨ï¼ŒåŒ…æ‹¬æ–‡æœ¬ã€è§†è§‰æ¨¡å‹
"""
import httpx
import json
from typing import List, Dict, AsyncGenerator, Optional
from ..config import AI_MODELS, settings


class AIService:
    """AI æœåŠ¡ç±»"""
    
    # å­¦ä¹ æ•™ç»ƒç³»ç»Ÿæç¤ºè¯
    COACH_SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šã€è€å¿ƒã€æœ‰çˆ±å¿ƒçš„AIå­¦ä¹ æ•™ç»ƒã€‚ä½ çš„ç›®æ ‡æ˜¯å¸®åŠ©å­¦ç”Ÿé«˜æ•ˆå­¦ä¹ ã€è§£ç­”ç–‘æƒ‘ã€åˆ¶å®šè®¡åˆ’ã€ç›‘ç£è¿›åº¦ã€‚

ä½ çš„ç‰¹ç‚¹ï¼š
1. ğŸ¯ ä¸“æ³¨å­¦ä¹ ï¼šæ‰€æœ‰å›ç­”éƒ½å›´ç»•å­¦ä¹ å’Œæ•™è‚²å±•å¼€
2. ğŸ’¡ å› ææ–½æ•™ï¼šæ ¹æ®å­¦ç”Ÿçš„æ°´å¹³å’Œç‰¹ç‚¹è°ƒæ•´è®²è§£æ–¹å¼
3. ğŸŒŸ ç§¯æé¼“åŠ±ï¼šé€‚æ—¶ç»™äºˆæ­£é¢åé¦ˆå’Œé¼“åŠ±
4. ğŸ“š çŸ¥è¯†ä¸°å¯Œï¼šèƒ½å¤Ÿè§£ç­”å„å­¦ç§‘çš„é—®é¢˜
5. ğŸ“‹ å–„äºè§„åˆ’ï¼šå¸®åŠ©å­¦ç”Ÿåˆ¶å®šåˆç†çš„å­¦ä¹ è®¡åˆ’

å›å¤æ ¼å¼è¦æ±‚ï¼š
- ä½¿ç”¨ Markdown æ ¼å¼è®©å›ç­”æ›´æ¸…æ™°
- é€‚å½“ä½¿ç”¨ emoji å¢åŠ äº²å’ŒåŠ›
- é‡è¦æ¦‚å¿µç”¨ç²—ä½“æ ‡æ³¨
- å¤æ‚å†…å®¹ç”¨åˆ—è¡¨æˆ–è¡¨æ ¼æ•´ç†
- å…¬å¼ä½¿ç”¨ LaTeX æ ¼å¼ï¼ˆ$...$ï¼‰"""
    
    @classmethod
    async def chat(
        cls,
        messages: List[Dict],
        model_type: str = "text",
        temperature: float = 0.7,
        max_tokens: int = 2000,
        user_memory: Optional[Dict] = None,
    ) -> str:
        """
        éæµå¼ AI å¯¹è¯
        
        Args:
            messages: å¯¹è¯å†å²
            model_type: æ¨¡å‹ç±»å‹ (text/vision/longtext)
            temperature: ç”Ÿæˆæ¸©åº¦
            max_tokens: æœ€å¤§ç”Ÿæˆé•¿åº¦
            user_memory: ç”¨æˆ·è®°å¿†/ç”»åƒ
        
        Returns:
            AI å›å¤å†…å®¹
        """
        config = AI_MODELS.get(model_type, AI_MODELS["text"])
        
        # æ„å»ºå®Œæ•´çš„æ¶ˆæ¯åˆ—è¡¨
        full_messages = cls._build_messages(messages, user_memory)
        
        async with httpx.AsyncClient(timeout=120.0) as client:
            response = await client.post(
                f"{config['base_url']}/chat/completions",
                headers={
                    "Content-Type": "application/json",
                    "Authorization": f"Bearer {config['api_key']}",
                },
                json={
                    "model": config["model"],
                    "messages": full_messages,
                    "temperature": temperature,
                    "max_tokens": max_tokens,
                    "stream": False,
                },
            )
            
            response.raise_for_status()
            data = response.json()
            
            if data.get("choices") and data["choices"][0].get("message"):
                return data["choices"][0]["message"]["content"]
            
            raise ValueError("AI è¿”å›æ ¼å¼é”™è¯¯")
    
    @classmethod
    async def chat_stream(
        cls,
        messages: List[Dict],
        model_type: str = "text",
        temperature: float = 0.7,
        max_tokens: int = 2000,
        user_memory: Optional[Dict] = None,
    ) -> AsyncGenerator[str, None]:
        """
        æµå¼ AI å¯¹è¯
        
        Args:
            messages: å¯¹è¯å†å²
            model_type: æ¨¡å‹ç±»å‹
            temperature: ç”Ÿæˆæ¸©åº¦
            max_tokens: æœ€å¤§ç”Ÿæˆé•¿åº¦
            user_memory: ç”¨æˆ·è®°å¿†/ç”»åƒ
        
        Yields:
            AI å›å¤å†…å®¹ç‰‡æ®µ
        """
        config = AI_MODELS.get(model_type, AI_MODELS["text"])
        
        # æ„å»ºå®Œæ•´çš„æ¶ˆæ¯åˆ—è¡¨
        full_messages = cls._build_messages(messages, user_memory)
        
        async with httpx.AsyncClient(timeout=120.0) as client:
            async with client.stream(
                "POST",
                f"{config['base_url']}/chat/completions",
                headers={
                    "Content-Type": "application/json",
                    "Authorization": f"Bearer {config['api_key']}",
                },
                json={
                    "model": config["model"],
                    "messages": full_messages,
                    "temperature": temperature,
                    "max_tokens": max_tokens,
                    "stream": True,
                },
            ) as response:
                response.raise_for_status()
                
                async for line in response.aiter_lines():
                    if line.startswith("data: "):
                        data_str = line[6:]
                        if data_str == "[DONE]":
                            break
                        
                        try:
                            data = json.loads(data_str)
                            if data.get("choices") and data["choices"][0].get("delta"):
                                content = data["choices"][0]["delta"].get("content", "")
                                if content:
                                    yield content
                        except json.JSONDecodeError:
                            continue
    
    @classmethod
    async def recognize_image(
        cls,
        image_url: str,
        recognize_type: str = "ocr",
        custom_prompt: Optional[str] = None,
    ) -> str:
        """
        å›¾ç‰‡è¯†åˆ«
        
        Args:
            image_url: å›¾ç‰‡ URL
            recognize_type: è¯†åˆ«ç±»å‹ (ocr/explain/summary/formula)
            custom_prompt: è‡ªå®šä¹‰æç¤ºè¯
        
        Returns:
            è¯†åˆ«ç»“æœ
        """
        # æ„å»ºæç¤ºè¯
        if custom_prompt:
            prompt = custom_prompt
        else:
            prompts = {
                "ocr": "è¯·è¯†åˆ«å¹¶æå–å›¾ç‰‡ä¸­çš„æ‰€æœ‰æ–‡å­—å†…å®¹ï¼Œä¿æŒåŸæœ‰çš„æ ¼å¼å’Œç»“æ„ã€‚å¦‚æœæœ‰è¡¨æ ¼ï¼Œè¯·ç”¨Markdownè¡¨æ ¼æ ¼å¼è¾“å‡ºã€‚",
                "explain": "è¯·è¯¦ç»†è§£é‡Šè¿™å¼ å›¾ç‰‡çš„å†…å®¹ï¼ŒåŒ…æ‹¬æ–‡å­—ã€å›¾è¡¨ã€å…¬å¼ç­‰ï¼Œå¹¶ç»™å‡ºé€šä¿—æ˜“æ‡‚çš„è§£é‡Šã€‚å¦‚æœæ˜¯å­¦ä¹ ææ–™ï¼Œè¯·é‡ç‚¹è§£æçŸ¥è¯†ç‚¹ã€‚",
                "summary": "è¯·ç”¨ç®€æ´çš„è¯­è¨€æ€»ç»“è¿™å¼ å›¾ç‰‡çš„ä¸»è¦å†…å®¹å’Œå…³é”®ä¿¡æ¯ã€‚åˆ—å‡º3-5ä¸ªè¦ç‚¹ã€‚",
                "formula": "è¯·è¯†åˆ«å›¾ç‰‡ä¸­çš„æ•°å­¦å…¬å¼æˆ–æ–¹ç¨‹å¼ï¼Œç”¨LaTeXæ ¼å¼è¾“å‡ºï¼ˆä½¿ç”¨$...$åŒ…è£¹ï¼‰ï¼Œå¹¶è§£é‡Šå…¶å«ä¹‰å’Œåº”ç”¨åœºæ™¯ã€‚",
            }
            prompt = prompts.get(recognize_type, "è¯·æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹ã€‚")
        
        config = AI_MODELS["vision"]
        
        messages = [
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {"type": "image_url", "image_url": {"url": image_url}},
                ],
            }
        ]
        
        async with httpx.AsyncClient(timeout=120.0) as client:
            response = await client.post(
                f"{config['base_url']}/chat/completions",
                headers={
                    "Content-Type": "application/json",
                    "Authorization": f"Bearer {config['api_key']}",
                },
                json={
                    "model": config["model"],
                    "messages": messages,
                    "max_tokens": config["max_tokens"],
                },
            )
            
            response.raise_for_status()
            data = response.json()
            
            if data.get("choices") and data["choices"][0].get("message"):
                return data["choices"][0]["message"]["content"]
            
            raise ValueError("è§†è§‰ AI è¿”å›æ ¼å¼é”™è¯¯")
    
    @classmethod
    async def analyze_mistake(
        cls,
        question: str,
        user_answer: str,
        correct_answer: Optional[str] = None,
        subject: str = "",
        image_url: Optional[str] = None,
    ) -> Dict:
        """
        é”™é¢˜åˆ†æ
        
        Args:
            question: é¢˜ç›®å†…å®¹
            user_answer: ç”¨æˆ·ç­”æ¡ˆ
            correct_answer: æ­£ç¡®ç­”æ¡ˆ
            subject: å­¦ç§‘
            image_url: é¢˜ç›®å›¾ç‰‡
        
        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        prompt = f"""è¯·åˆ†æä»¥ä¸‹é”™é¢˜ï¼Œç»™å‡ºè¯¦ç»†çš„åˆ†æå’Œå»ºè®®ã€‚

ã€é¢˜ç›®ã€‘
{question}

ã€å­¦ç”Ÿç­”æ¡ˆã€‘
{user_answer}

{"ã€æ­£ç¡®ç­”æ¡ˆã€‘" + chr(10) + correct_answer if correct_answer else ""}

{"ã€å­¦ç§‘ã€‘" + subject if subject else ""}

è¯·æŒ‰ä»¥ä¸‹JSONæ ¼å¼è¿”å›åˆ†æç»“æœï¼ˆåªè¿”å›JSONï¼‰ï¼š
{{
    "error_type": "é”™è¯¯ç±»å‹ï¼ˆå¦‚ï¼šæ¦‚å¿µç†è§£é”™è¯¯ã€è®¡ç®—å¤±è¯¯ã€å®¡é¢˜ä¸æ¸…ç­‰ï¼‰",
    "error_reason": "è¯¦ç»†çš„é”™è¯¯åŸå› åˆ†æ",
    "correct_solution": "æ­£ç¡®çš„è§£é¢˜è¿‡ç¨‹å’Œç­”æ¡ˆ",
    "knowledge_points": ["æ¶‰åŠçš„çŸ¥è¯†ç‚¹1", "çŸ¥è¯†ç‚¹2"],
    "similar_questions": ["ç±»ä¼¼é¢˜ç›®çš„æè¿°1", "ç±»ä¼¼é¢˜ç›®2"],
    "study_suggestions": ["å­¦ä¹ å»ºè®®1", "å»ºè®®2", "å»ºè®®3"]
}}"""

        # å¦‚æœæœ‰å›¾ç‰‡ï¼Œä½¿ç”¨è§†è§‰æ¨¡å‹
        if image_url:
            config = AI_MODELS["vision"]
            messages = [
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt},
                        {"type": "image_url", "image_url": {"url": image_url}},
                    ],
                }
            ]
        else:
            config = AI_MODELS["text"]
            messages = [{"role": "user", "content": prompt}]
        
        async with httpx.AsyncClient(timeout=120.0) as client:
            response = await client.post(
                f"{config['base_url']}/chat/completions",
                headers={
                    "Content-Type": "application/json",
                    "Authorization": f"Bearer {config['api_key']}",
                },
                json={
                    "model": config["model"],
                    "messages": messages,
                    "max_tokens": 2000,
                    "temperature": 0.7,
                },
            )
            
            response.raise_for_status()
            data = response.json()
            
            if data.get("choices") and data["choices"][0].get("message"):
                content = data["choices"][0]["message"]["content"]
                
                # è§£æ JSON
                import re
                json_match = re.search(r'\{[\s\S]*\}', content)
                if json_match:
                    return json.loads(json_match.group())
            
            raise ValueError("é”™é¢˜åˆ†æè¿”å›æ ¼å¼é”™è¯¯")
    
    @classmethod
    def _build_messages(
        cls,
        messages: List[Dict],
        user_memory: Optional[Dict] = None,
    ) -> List[Dict]:
        """
        æ„å»ºå®Œæ•´çš„æ¶ˆæ¯åˆ—è¡¨ï¼ŒåŒ…å«ç³»ç»Ÿæç¤ºå’Œç”¨æˆ·è®°å¿†
        """
        full_messages = []
        
        # 1. æ·»åŠ ç³»ç»Ÿæç¤ºè¯
        system_prompt = cls.COACH_SYSTEM_PROMPT
        
        # 2. å¦‚æœæœ‰ç”¨æˆ·è®°å¿†ï¼Œæ·»åŠ åˆ°ç³»ç»Ÿæç¤ºä¸­
        if user_memory:
            memory_info = cls._format_user_memory(user_memory)
            if memory_info:
                system_prompt += f"\n\nã€ç”¨æˆ·æ¡£æ¡ˆã€‘\n{memory_info}"
        
        full_messages.append({"role": "system", "content": system_prompt})
        
        # 3. æ·»åŠ å¯¹è¯å†å²
        for msg in messages:
            full_messages.append({
                "role": msg.get("role", "user"),
                "content": msg.get("content", ""),
            })
        
        return full_messages
    
    @classmethod
    def _format_user_memory(cls, memory: Dict) -> str:
        """æ ¼å¼åŒ–ç”¨æˆ·è®°å¿†ä¸ºæ–‡æœ¬"""
        parts = []
        
        profile = memory.get("profile", {})
        if profile.get("name"):
            parts.append(f"- ç§°å‘¼ï¼š{profile['name']}")
        if profile.get("grade"):
            parts.append(f"- å¹´çº§/èŒä¸šï¼š{profile['grade']}")
        if profile.get("learningGoals"):
            parts.append(f"- å­¦ä¹ ç›®æ ‡ï¼š{', '.join(profile['learningGoals'])}")
        if profile.get("subjects"):
            parts.append(f"- æ­£åœ¨å­¦ä¹ ï¼š{', '.join(profile['subjects'])}")
        if profile.get("weakPoints"):
            parts.append(f"- è–„å¼±ç‚¹ï¼š{', '.join(profile['weakPoints'])}")
        
        facts = memory.get("facts", [])
        if facts:
            recent_facts = [f["fact"] for f in facts[-5:]]
            parts.append(f"- é‡è¦ä¿¡æ¯ï¼š{'; '.join(recent_facts)}")
        
        return "\n".join(parts) if parts else ""

