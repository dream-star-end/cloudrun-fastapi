"""
å›¾ç‰‡è¯†åˆ«å·¥å…·
åŸºäºŽ LangChain 1.0 çš„ @tool è£…é¥°å™¨
"""

from langchain_core.tools import tool, BaseTool
from langchain_openai import ChatOpenAI

from ...config import settings


@tool
async def recognize_image(
    image_url: str,
    recognize_type: str = "auto",
    custom_prompt: str = "",
) -> str:
    """è¯†åˆ«å›¾ç‰‡ä¸­çš„å†…å®¹ã€‚
    
    æ”¯æŒä»¥ä¸‹åŠŸèƒ½ï¼š
    - OCRæ–‡å­—è¯†åˆ«ï¼šæå–å›¾ç‰‡ä¸­çš„æ–‡å­—
    - å…¬å¼è¯†åˆ«ï¼šè¯†åˆ«æ•°å­¦å…¬å¼å¹¶è½¬ä¸ºLaTeX
    - å›¾ç‰‡è§£é‡Šï¼šè§£é‡Šå›¾ç‰‡å†…å®¹å’Œå«ä¹‰
    
    é€‚ç”¨äºŽç”¨æˆ·ä¸Šä¼ é¢˜ç›®å›¾ç‰‡ã€ç¬”è®°å›¾ç‰‡ã€å…¬å¼å›¾ç‰‡ç­‰åœºæ™¯ã€‚
    
    Args:
        image_url: å›¾ç‰‡URLåœ°å€ï¼ˆå¿…é¡»æ˜¯å…¬ç½‘å¯è®¿é—®çš„URLï¼‰
        recognize_type: è¯†åˆ«ç±»åž‹ ocr/formula/explain/autoï¼Œé»˜è®¤auto
        custom_prompt: è‡ªå®šä¹‰è¯†åˆ«æç¤ºè¯ï¼ˆå¯é€‰ï¼‰
    
    Returns:
        è¯†åˆ«ç»“æžœ
    """
    # æ ¹æ®è¯†åˆ«ç±»åž‹é€‰æ‹©æç¤ºè¯
    prompts = {
        "ocr": """è¯·ä»”ç»†è¯†åˆ«å›¾ç‰‡ä¸­çš„æ‰€æœ‰æ–‡å­—å†…å®¹ã€‚
è¦æ±‚ï¼š
1. ä¿æŒåŽŸæœ‰çš„æ ¼å¼å’Œå¸ƒå±€
2. å¦‚æžœæœ‰è¡¨æ ¼ï¼Œç”¨markdownè¡¨æ ¼æ ¼å¼è¾“å‡º
3. å¦‚æžœæœ‰å…¬å¼ï¼Œç”¨LaTeXæ ¼å¼è¡¨ç¤º
4. æ ‡æ³¨ä»»ä½•ä¸ç¡®å®šçš„æ–‡å­—""",
        
        "formula": """è¯·è¯†åˆ«å›¾ç‰‡ä¸­çš„æ•°å­¦å…¬å¼ã€‚
è¦æ±‚ï¼š
1. å°†å…¬å¼è½¬æ¢ä¸ºæ ‡å‡†LaTeXæ ¼å¼
2. å¦‚æžœæœ‰å¤šä¸ªå…¬å¼ï¼Œæ¯ä¸ªå…¬å¼å•ç‹¬ä¸€è¡Œ
3. ç®€è¦è¯´æ˜Žå…¬å¼çš„å«ä¹‰
4. å¦‚æžœå…¬å¼æœ‰ç¼–å·ï¼Œä¿ç•™ç¼–å·""",
        
        "explain": """è¯·è¯¦ç»†è§£é‡Šè¿™å¼ å›¾ç‰‡çš„å†…å®¹ã€‚
è¦æ±‚ï¼š
1. æè¿°å›¾ç‰‡ä¸­çš„ä¸»è¦å…ƒç´ 
2. è§£é‡Šå›¾ç‰‡è¦ä¼ è¾¾çš„ä¿¡æ¯æˆ–çŸ¥è¯†ç‚¹
3. å¦‚æžœæ˜¯é¢˜ç›®ï¼Œè¯´æ˜Žè§£é¢˜æ€è·¯
4. å¦‚æžœæœ‰å›¾è¡¨ï¼Œåˆ†æžæ•°æ®å«ä¹‰""",
        
        "auto": """è¯·åˆ†æžè¿™å¼ å›¾ç‰‡çš„å†…å®¹ã€‚
1. é¦–å…ˆåˆ¤æ–­å›¾ç‰‡ç±»åž‹ï¼ˆé¢˜ç›®ã€å…¬å¼ã€ç¬”è®°ã€å›¾è¡¨ç­‰ï¼‰
2. æ ¹æ®ç±»åž‹è¿›è¡Œç›¸åº”å¤„ç†ï¼š
   - å¦‚æžœæ˜¯æ–‡å­—ï¼Œè¿›è¡ŒOCRè¯†åˆ«
   - å¦‚æžœæ˜¯å…¬å¼ï¼Œè½¬æ¢ä¸ºLaTeX
   - å¦‚æžœæ˜¯é¢˜ç›®ï¼Œæå–é¢˜ç›®å¹¶ç»™å‡ºè§£é¢˜æ€è·¯
   - å¦‚æžœæ˜¯å›¾è¡¨ï¼Œåˆ†æžæ•°æ®å«ä¹‰""",
    }
    
    prompt = custom_prompt if custom_prompt else prompts.get(recognize_type, prompts["auto"])
    
    try:
        # ä½¿ç”¨è§†è§‰æ¨¡åž‹
        llm = ChatOpenAI(
            model=settings.DEEPSEEK_VISION_MODEL,
            api_key=settings.DEEPSEEK_API_KEY,
            base_url=settings.DEEPSEEK_API_BASE,
            temperature=0.3,
        )
        
        messages = [
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {"type": "image_url", "image_url": {"url": image_url}},
                ],
            }
        ]
        
        response = await llm.ainvoke(messages)
        
        type_names = {
            "ocr": "ðŸ“ æ–‡å­—è¯†åˆ«ç»“æžœ",
            "formula": "ðŸ“ å…¬å¼è¯†åˆ«ç»“æžœ",
            "explain": "ðŸ” å›¾ç‰‡è§£æž",
            "auto": "ðŸ“¸ è¯†åˆ«ç»“æžœ",
        }
        
        title = type_names.get(recognize_type, "è¯†åˆ«ç»“æžœ")
        return f"{title}ï¼š\n\n{response.content}"
        
    except Exception as e:
        return f"å›¾ç‰‡è¯†åˆ«å¤±è´¥: {str(e)}"


def recognize_image_tool() -> BaseTool:
    """è¿”å›žå›¾ç‰‡è¯†åˆ«å·¥å…·"""
    return recognize_image
