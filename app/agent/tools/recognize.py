"""
å›¾ç‰‡è¯†åˆ«å·¥å…·
åŸºäºŽ LangChain 1.0 çš„ @tool è£…é¥°å™¨

æ³¨æ„ï¼šæ­¤å·¥å…·éœ€è¦ç”¨æˆ·é…ç½®æ”¯æŒè§†è§‰çš„æ¨¡åž‹ï¼ˆå¦‚ GPT-4oï¼‰
DeepSeek ä¸æ”¯æŒå›¾ç‰‡è¯†åˆ«
"""

from langchain_core.tools import tool, BaseTool
from langchain_openai import ChatOpenAI

from ...config import settings
from ...services.model_config_service import ModelConfigService


async def _get_vision_llm(user_id: str = None):
    """
    èŽ·å–è§†è§‰æ¨¡åž‹ LLM å®žä¾‹
    
    ä¼˜å…ˆä½¿ç”¨ç”¨æˆ·é…ç½®çš„å¤šæ¨¡æ€æ¨¡åž‹ï¼Œå¦åˆ™ä½¿ç”¨ç³»ç»Ÿé»˜è®¤é…ç½®
    """
    if user_id:
        try:
            model_config = await ModelConfigService.get_model_for_type(user_id, "multimodal")
            if model_config.get("api_key"):
                return ChatOpenAI(
                    model=model_config["model"],
                    api_key=model_config["api_key"],
                    base_url=model_config["base_url"],
                    temperature=0.3,
                )
        except Exception:
            pass
    
    # é™çº§ï¼šä½¿ç”¨ç³»ç»Ÿé»˜è®¤è§†è§‰æ¨¡åž‹é…ç½®ï¼ˆéœ€è¦ç”¨æˆ·åœ¨å°ç¨‹åºä¸­é…ç½®ï¼‰
    return ChatOpenAI(
        model=settings.VISION_MODEL,
        api_key="",  # éœ€è¦ç”¨æˆ·é…ç½®
        base_url=settings.VISION_BASE_URL,
        temperature=0.3,
    )


@tool
async def recognize_image(
    image_url: str,
    recognize_type: str = "auto",
    custom_prompt: str = "",
) -> str:
    """è¯†åˆ«å›¾ç‰‡ä¸­çš„å†…å®¹ã€‚
    
    æ”¯æŒä»¥ä¸‹åŠŸèƒ½ï¼š
    - OCRæ–‡å­—è¯†åˆ«ï¼šæå–å›¾ç‰‡ä¸­çš„æ–‡å­—
    - å…¬å¼è¯†åˆ«ï¼šè¯†åˆ«æ•°å­¦å…¬å¼å¹¶è½¬ä¸ºLaTeX
    - å›¾ç‰‡è§£é‡Šï¼šè§£é‡Šå›¾ç‰‡å†…å®¹å’Œå«ä¹‰
    
    é€‚ç”¨äºŽç”¨æˆ·ä¸Šä¼ é¢˜ç›®å›¾ç‰‡ã€ç¬”è®°å›¾ç‰‡ã€å…¬å¼å›¾ç‰‡ç­‰åœºæ™¯ã€‚
    
    Args:
        image_url: å›¾ç‰‡URLåœ°å€ï¼ˆå¿…é¡»æ˜¯å…¬ç½‘å¯è®¿é—®çš„URLï¼‰
        recognize_type: è¯†åˆ«ç±»åž‹ ocr/formula/explain/autoï¼Œé»˜è®¤auto
        custom_prompt: è‡ªå®šä¹‰è¯†åˆ«æç¤ºè¯ï¼ˆå¯é€‰ï¼‰
    
    Returns:
        è¯†åˆ«ç»“æžœ
    """
    # æ ¹æ®è¯†åˆ«ç±»åž‹é€‰æ‹©æç¤ºè¯
    prompts = {
        "ocr": """è¯·ä»”ç»†è¯†åˆ«å›¾ç‰‡ä¸­çš„æ‰€æœ‰æ–‡å­—å†…å®¹ã€‚
è¦æ±‚ï¼š
1. ä¿æŒåŽŸæœ‰çš„æ ¼å¼å’Œå¸ƒå±€
2. å¦‚æžœæœ‰è¡¨æ ¼ï¼Œç”¨markdownè¡¨æ ¼æ ¼å¼è¾“å‡º
3. å¦‚æžœæœ‰å…¬å¼ï¼Œç”¨LaTeXæ ¼å¼è¡¨ç¤º
4. æ ‡æ³¨ä»»ä½•ä¸ç¡®å®šçš„æ–‡å­—""",
        
        "formula": """è¯·è¯†åˆ«å›¾ç‰‡ä¸­çš„æ•°å­¦å…¬å¼ã€‚
è¦æ±‚ï¼š
1. å°†å…¬å¼è½¬æ¢ä¸ºæ ‡å‡†LaTeXæ ¼å¼
2. å¦‚æžœæœ‰å¤šä¸ªå…¬å¼ï¼Œæ¯ä¸ªå…¬å¼å•ç‹¬ä¸€è¡Œ
3. ç®€è¦è¯´æ˜Žå…¬å¼çš„å«ä¹‰
4. å¦‚æžœå…¬å¼æœ‰ç¼–å·ï¼Œä¿ç•™ç¼–å·""",
        
        "explain": """è¯·è¯¦ç»†è§£é‡Šè¿™å¼ å›¾ç‰‡çš„å†…å®¹ã€‚
è¦æ±‚ï¼š
1. æè¿°å›¾ç‰‡ä¸­çš„ä¸»è¦å…ƒç´ 
2. è§£é‡Šå›¾ç‰‡è¦ä¼ è¾¾çš„ä¿¡æ¯æˆ–çŸ¥è¯†ç‚¹
3. å¦‚æžœæ˜¯é¢˜ç›®ï¼Œè¯´æ˜Žè§£é¢˜æ€è·¯
4. å¦‚æžœæœ‰å›¾è¡¨ï¼Œåˆ†æžæ•°æ®å«ä¹‰""",
        
        "auto": """è¯·åˆ†æžè¿™å¼ å›¾ç‰‡çš„å†…å®¹ã€‚
1. é¦–å…ˆåˆ¤æ–­å›¾ç‰‡ç±»åž‹ï¼ˆé¢˜ç›®ã€å…¬å¼ã€ç¬”è®°ã€å›¾è¡¨ç­‰ï¼‰
2. æ ¹æ®ç±»åž‹è¿›è¡Œç›¸åº”å¤„ç†ï¼š
   - å¦‚æžœæ˜¯æ–‡å­—ï¼Œè¿›è¡ŒOCRè¯†åˆ«
   - å¦‚æžœæ˜¯å…¬å¼ï¼Œè½¬æ¢ä¸ºLaTeX
   - å¦‚æžœæ˜¯é¢˜ç›®ï¼Œæå–é¢˜ç›®å¹¶ç»™å‡ºè§£é¢˜æ€è·¯
   - å¦‚æžœæ˜¯å›¾è¡¨ï¼Œåˆ†æžæ•°æ®å«ä¹‰""",
    }
    
    prompt = custom_prompt if custom_prompt else prompts.get(recognize_type, prompts["auto"])
    
    try:
        # ä½¿ç”¨è§†è§‰æ¨¡åž‹ï¼ˆéœ€è¦ç”¨æˆ·é…ç½®æ”¯æŒè§†è§‰çš„æ¨¡åž‹ï¼Œå¦‚ GPT-4oï¼‰
        # æ³¨æ„ï¼šDeepSeek ä¸æ”¯æŒå›¾ç‰‡è¯†åˆ«
        llm = await _get_vision_llm()
        
        messages = [
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {"type": "image_url", "image_url": {"url": image_url}},
                ],
            }
        ]
        
        response = await llm.ainvoke(messages)
        
        type_names = {
            "ocr": "ðŸ“ æ–‡å­—è¯†åˆ«ç»“æžœ",
            "formula": "ðŸ“ å…¬å¼è¯†åˆ«ç»“æžœ",
            "explain": "ðŸ” å›¾ç‰‡è§£æž",
            "auto": "ðŸ“¸ è¯†åˆ«ç»“æžœ",
        }
        
        title = type_names.get(recognize_type, "è¯†åˆ«ç»“æžœ")
        return f"{title}ï¼š\n\n{response.content}"
        
    except Exception as e:
        return f"å›¾ç‰‡è¯†åˆ«å¤±è´¥: {str(e)}"


def recognize_image_tool() -> BaseTool:
    """è¿”å›žå›¾ç‰‡è¯†åˆ«å·¥å…·"""
    return recognize_image
