"""
AI Agent æ ¸å¿ƒæ¨¡å—
åŸºäº LangChain 1.0 + LangGraph çš„æ™ºèƒ½ä»£ç†

ç‰¹ç‚¹ï¼š
- è‡ªä¸»å†³ç­–ï¼šæ ¹æ®ç”¨æˆ·æ„å›¾é€‰æ‹©åˆé€‚çš„å·¥å…·
- å¤šè½®å¯¹è¯ï¼šä¿æŒä¸Šä¸‹æ–‡è¿è´¯æ€§
- è‡ªæˆ‘åæ€ï¼šè¯„ä¼°æ‰§è¡Œç»“æœå¹¶ä¼˜åŒ–ç­–ç•¥
- æµå¼è¾“å‡ºï¼šæ”¯æŒå®æ—¶å“åº”
"""

import json
from typing import AsyncIterator, Optional, Dict, Any, List
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage
from langgraph.prebuilt import create_react_agent
from langgraph.checkpoint.memory import MemorySaver

from .tools import get_all_tools
from .memory import AgentMemory
from ..config import settings


# AI å­¦ä¹ æ•™ç»ƒç³»ç»Ÿæç¤ºè¯
LEARNING_COACH_PROMPT = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ AI å­¦ä¹ æ•™ç»ƒï¼Œåå«"å°æ™º"ã€‚ä½ çš„èŒè´£æ˜¯å¸®åŠ©ç”¨æˆ·é«˜æ•ˆå­¦ä¹ ã€è§£å†³å­¦ä¹ ä¸­çš„é—®é¢˜ã€‚

## ä½ çš„èƒ½åŠ›
ä½ æ‹¥æœ‰ä»¥ä¸‹å·¥å…·ï¼Œå¯ä»¥æ ¹æ®éœ€è¦è°ƒç”¨ï¼š

### ğŸ“š å­¦ä¹ è®¡åˆ’
- **create_learning_plan**: ä¸ºç”¨æˆ·åˆ›å»ºä¸ªæ€§åŒ–å­¦ä¹ è®¡åˆ’
- **generate_daily_tasks**: ç”Ÿæˆæ¯æ—¥å­¦ä¹ ä»»åŠ¡

### ğŸ” æœç´¢ä¸è¯†åˆ«
- **search_resources**: è”ç½‘æœç´¢å­¦ä¹ èµ„æºå’Œèµ„æ–™
- **search_learning_materials**: æœç´¢ç‰¹å®šå­¦ä¹ ææ–™
- **recognize_image**: è¯†åˆ«å›¾ç‰‡å†…å®¹ï¼ˆOCRã€å…¬å¼ã€è§£é‡Šç­‰ï¼‰

### ğŸ“ ä»»åŠ¡ç®¡ç†
- **get_today_tasks**: è·å–ä»Šæ—¥å­¦ä¹ ä»»åŠ¡åˆ—è¡¨
- **complete_task**: æ ‡è®°ä»»åŠ¡ä¸ºå·²å®Œæˆ
- **get_task_progress**: æŸ¥çœ‹ä»»åŠ¡å®Œæˆè¿›åº¦
- **suggest_task_adjustment**: å»ºè®®è°ƒæ•´ä»»åŠ¡å®‰æ’

### âœ… æ‰“å¡ç³»ç»Ÿ
- **do_checkin**: æ‰§è¡Œå­¦ä¹ æ‰“å¡
- **get_checkin_status**: è·å–æ‰“å¡çŠ¶æ€å’Œç»Ÿè®¡
- **get_badges**: è·å–æˆå°±å¾½ç« åˆ—è¡¨

### ğŸ… ç•ªèŒ„ä¸“æ³¨
- **get_focus_stats**: è·å–ä¸“æ³¨æ—¶é—´ç»Ÿè®¡
- **suggest_focus_plan**: å»ºè®®ä¸“æ³¨è®¡åˆ’å®‰æ’

### ğŸ“• é”™é¢˜æœ¬
- **get_mistakes**: è·å–é”™é¢˜åˆ—è¡¨
- **add_mistake**: æ·»åŠ æ–°é”™é¢˜
- **analyze_mistake**: AIåˆ†æé”™é¢˜åŸå› 
- **generate_review_questions**: ç”Ÿæˆå¤ä¹ é¢˜
- **mark_mistake_mastered**: æ ‡è®°é”™é¢˜å·²æŒæ¡

### ğŸ“Š ç»Ÿè®¡åˆ†æ
- **get_learning_stats**: è·å–å­¦ä¹ ç»Ÿè®¡æ•°æ®
- **get_ranking**: è·å–å­¦ä¹ æ’è¡Œæ¦œ
- **get_achievement_rate**: è·å–ç›®æ ‡è¾¾æˆç‡
- **analyze_learning_pattern**: åˆ†æå­¦ä¹ æ¨¡å¼
- **get_calendar_data**: è·å–æ—¥å†å­¦ä¹ è¯¦æƒ…
- **analyze_learning_status**: åˆ†ææ•´ä½“å­¦ä¹ çŠ¶æ€

### ğŸ‘¤ ç”¨æˆ·ç”»åƒ
- **update_user_profile**: æ›´æ–°ç”¨æˆ·å­¦ä¹ ç”»åƒ
- **get_user_stats**: è·å–ç”¨æˆ·ç»Ÿè®¡ä¿¡æ¯

## ç”¨æˆ·ç”»åƒ
{user_profile}

## å¯¹è¯è®°å¿†
{conversation_summary}

## è¡Œä¸ºå‡†åˆ™
1. **ä¸»åŠ¨å…³æ€€**: å…³æ³¨ç”¨æˆ·çš„å­¦ä¹ çŠ¶æ€å’Œæƒ…ç»ªï¼Œé€‚æ—¶ç»™äºˆé¼“åŠ±
2. **å› ææ–½æ•™**: æ ¹æ®ç”¨æˆ·ç”»åƒè°ƒæ•´æ•™å­¦é£æ ¼å’Œéš¾åº¦
3. **å¾ªåºæ¸è¿›**: å°†å¤æ‚ä»»åŠ¡åˆ†è§£ä¸ºå¯æ‰§è¡Œçš„å°æ­¥éª¤
4. **æŒç»­ä¼˜åŒ–**: æ ¹æ®ç”¨æˆ·åé¦ˆä¸æ–­æ”¹è¿›å»ºè®®
5. **ç®€æ´é«˜æ•ˆ**: å›å¤ç®€æ´æ˜äº†ï¼Œé¿å…å†—é•¿
6. **å–„ç”¨å·¥å…·**: æ ¹æ®ç”¨æˆ·éœ€æ±‚ä¸»åŠ¨è°ƒç”¨åˆé€‚çš„å·¥å…·

## å›å¤é£æ ¼
- å‹å¥½äº²åˆ‡ï¼Œåƒæœ‹å‹ä¸€æ ·äº¤æµ
- ä½¿ç”¨ç®€æ´çš„ä¸­æ–‡
- é€‚å½“ä½¿ç”¨ emoji å¢åŠ äº²å’ŒåŠ›
- ç»™å‡ºå…·ä½“å¯æ‰§è¡Œçš„å»ºè®®
- å¼•å¯¼ç”¨æˆ·ä½¿ç”¨å°ç¨‹åºçš„å„é¡¹åŠŸèƒ½

å½“å‰æ—¶é—´: {current_time}
"""

# AI ä¼´è¯»åŠ©æ‰‹ç³»ç»Ÿæç¤ºè¯
READING_COMPANION_PROMPT = """ä½ æ˜¯ä¸€ä½æ™ºèƒ½ä¼´è¯»åŠ©æ‰‹ï¼Œåå«"å°æ™º"ã€‚ä½ çš„èŒè´£æ˜¯å¸®åŠ©ç”¨æˆ·é˜…è¯»å’Œç†è§£å„ç§å­¦ä¹ ææ–™ã€‚

## ä½ çš„èƒ½åŠ›
ä½ æ‹¥æœ‰ä»¥ä¸‹å·¥å…·ï¼Œå¯ä»¥æ ¹æ®éœ€è¦è°ƒç”¨ï¼š

### ğŸ” è¯†åˆ«ä¸æœç´¢
- **recognize_image**: è¯†åˆ«å›¾ç‰‡ä¸­çš„æ–‡å­—ã€å…¬å¼ã€å›¾è¡¨
- **search_resources**: æœç´¢ç›¸å…³çš„è¡¥å……èµ„æ–™
- **search_learning_materials**: æœç´¢å­¦ä¹ ææ–™

### ğŸ“ å­¦ä¹ è¾…åŠ©
- **analyze_mistake**: åˆ†æé”™é¢˜ï¼Œæ‰¾å‡ºé—®é¢˜æ‰€åœ¨
- **add_mistake**: å°†é¢˜ç›®æ·»åŠ åˆ°é”™é¢˜æœ¬
- **generate_review_questions**: ç”Ÿæˆç»ƒä¹ é¢˜æ£€éªŒç†è§£

### ğŸ“Š è¿›åº¦è¿½è¸ª
- **get_today_tasks**: æŸ¥çœ‹ä»Šæ—¥ä»»åŠ¡
- **complete_task**: å®Œæˆå­¦ä¹ ä»»åŠ¡
- **get_learning_stats**: è·å–å­¦ä¹ ç»Ÿè®¡

## ç”¨æˆ·ç”»åƒ
{user_profile}

## é˜…è¯»ä¸Šä¸‹æ–‡
{reading_context}

## è¡Œä¸ºå‡†åˆ™
1. **æ·±å…¥æµ…å‡º**: ç”¨é€šä¿—æ˜“æ‡‚çš„è¯­è¨€è§£é‡Šå¤æ‚æ¦‚å¿µ
2. **ä¸¾ä¸€åä¸‰**: é€šè¿‡ä¾‹å­å’Œç±»æ¯”å¸®åŠ©ç†è§£
3. **äº’åŠ¨å­¦ä¹ **: é€‚æ—¶æé—®ï¼Œæ£€éªŒç”¨æˆ·ç†è§£ç¨‹åº¦
4. **çŸ¥è¯†å…³è”**: å°†æ–°çŸ¥è¯†ä¸å·²å­¦å†…å®¹å»ºç«‹è”ç³»
5. **é¼“åŠ±æ€è€ƒ**: å¼•å¯¼ç”¨æˆ·ä¸»åŠ¨æ€è€ƒè€Œéè¢«åŠ¨æ¥å—
6. **å–„ç”¨å·¥å…·**: é‡åˆ°é—®é¢˜æ—¶ä¸»åŠ¨è°ƒç”¨å·¥å…·è¾…åŠ©

å½“å‰æ—¶é—´: {current_time}
"""


class LearningAgent:
    """
    AI å­¦ä¹ æ•™ç»ƒ/ä¼´è¯» Agent
    
    åŸºäº LangChain 1.0 + LangGraph å®ç°
    - ä½¿ç”¨ create_react_agent åˆ›å»º ReAct é£æ ¼çš„æ™ºèƒ½ä½“
    - æ”¯æŒå·¥å…·è°ƒç”¨å’Œå¤šè½®å¯¹è¯
    - å†…ç½®è®°å¿†ç®¡ç†å’Œç”¨æˆ·ç”»åƒ
    """
    
    def __init__(
        self,
        user_id: str,
        mode: str = "coach",  # "coach" æˆ– "reader"
        memory: Optional[AgentMemory] = None,
    ):
        self.user_id = user_id
        self.mode = mode
        self.memory = memory or AgentMemory(user_id)
        
        # åˆå§‹åŒ– LLM
        self.llm = ChatOpenAI(
            model=settings.DEEPSEEK_MODEL,
            api_key=settings.DEEPSEEK_API_KEY,
            base_url=settings.DEEPSEEK_API_BASE,
            temperature=0.7,
            streaming=True,
        )
        
        # è·å–å·¥å…·
        self.tools = get_all_tools(user_id=user_id, memory=self.memory)
        
        # LangGraph æ£€æŸ¥ç‚¹ï¼ˆç”¨äºå¯¹è¯çŠ¶æ€æŒä¹…åŒ–ï¼‰
        self.checkpointer = MemorySaver()
        
        # åˆ›å»º Agent
        self._create_agent()
    
    def _create_agent(self):
        """
        åˆ›å»º LangGraph ReAct Agent
        
        LangChain 1.0 æ¨èä½¿ç”¨ LangGraph çš„ create_react_agent
        è¿™æ˜¯ä¸€ä¸ªæ›´çµæ´»ã€å¯æ§çš„ Agent å®ç°æ–¹å¼
        
        æ³¨æ„ï¼šLangGraph 0.2.x+ ä¸­ state_modifier å‚æ•°å·²è¢«ç§»é™¤
        ç³»ç»Ÿæç¤ºç°åœ¨é€šè¿‡ SystemMessage åœ¨ chat() å’Œ chat_stream() ä¸­åŠ¨æ€æ·»åŠ 
        è¿™æ ·å¯ä»¥æ”¯æŒåŠ¨æ€çš„ç”¨æˆ·ç”»åƒå’Œå¯¹è¯æ‘˜è¦æ³¨å…¥
        """
        # ä½¿ç”¨ LangGraph åˆ›å»º ReAct Agent
        # create_react_agent è¿”å›ä¸€ä¸ª CompiledGraph
        # ç³»ç»Ÿæç¤ºé€šè¿‡ _build_system_message() åŠ¨æ€æ„å»ºå¹¶ä½œä¸º SystemMessage æ·»åŠ 
        self.agent = create_react_agent(
            model=self.llm,
            tools=self.tools,
            checkpointer=self.checkpointer,  # å¯ç”¨å¯¹è¯çŠ¶æ€æŒä¹…åŒ–
        )
    
    async def chat(
        self,
        message: str,
        context: Optional[Dict[str, Any]] = None,
    ) -> str:
        """
        ä¸ Agent å¯¹è¯ï¼ˆéæµå¼ï¼‰
        
        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            context: é¢å¤–ä¸Šä¸‹æ–‡ï¼ˆå¦‚å½“å‰é˜…è¯»çš„å†…å®¹ï¼‰
            
        Returns:
            Agent å›å¤
        """
        # å‡†å¤‡è¾“å…¥
        input_data = self._prepare_input(message, context)
        
        # é…ç½®çº¿ç¨‹ IDï¼ˆç”¨äºå¤šè½®å¯¹è¯ï¼‰
        config = {"configurable": {"thread_id": self.user_id}}
        
        # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
        messages = [HumanMessage(content=message)]
        
        # å¦‚æœæœ‰ç³»ç»Ÿæç¤ºï¼Œæ·»åŠ ä¸Šä¸‹æ–‡
        if input_data.get("user_profile"):
            system_content = self._build_system_message(input_data)
            messages.insert(0, SystemMessage(content=system_content))
        
        # æ‰§è¡Œ Agent
        result = await self.agent.ainvoke(
            {"messages": messages},
            config=config,
        )
        
        # æå–æœ€ç»ˆå›å¤
        output = ""
        if result.get("messages"):
            last_message = result["messages"][-1]
            if hasattr(last_message, 'content'):
                output = last_message.content
        
        # ä¿å­˜å¯¹è¯è®°å½•
        await self.memory.add_message("user", message)
        await self.memory.add_message("assistant", output)
        
        # åˆ†æå¹¶æ›´æ–°ç”¨æˆ·ç”»åƒ
        await self._analyze_and_evolve(message, {"output": output})
        
        return output
    
    async def chat_stream(
        self,
        message: str,
        context: Optional[Dict[str, Any]] = None,
    ) -> AsyncIterator[str]:
        """
        ä¸ Agent å¯¹è¯ï¼ˆæµå¼ï¼‰
        
        ä½¿ç”¨ LangGraph çš„ astream_events API å®ç°æµå¼è¾“å‡º
        
        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            context: é¢å¤–ä¸Šä¸‹æ–‡
            
        Yields:
            Agent å›å¤çš„æ–‡æœ¬å—
        """
        # å‡†å¤‡è¾“å…¥
        input_data = self._prepare_input(message, context)
        
        # é…ç½®
        config = {"configurable": {"thread_id": self.user_id}}
        
        # æ„å»ºæ¶ˆæ¯
        messages = [HumanMessage(content=message)]
        if input_data.get("user_profile"):
            system_content = self._build_system_message(input_data)
            messages.insert(0, SystemMessage(content=system_content))
        
        full_response = ""
        
        # ä½¿ç”¨ astream_events è¿›è¡Œæµå¼å¤„ç†
        async for event in self.agent.astream_events(
            {"messages": messages},
            config=config,
            version="v2",
        ):
            kind = event["event"]
            
            # å¤„ç† LLM æµå¼è¾“å‡º
            if kind == "on_chat_model_stream":
                chunk = event.get("data", {}).get("chunk")
                if chunk and hasattr(chunk, 'content') and chunk.content:
                    content = chunk.content
                    full_response += content
                    yield content
            
            # å¤„ç†å·¥å…·è°ƒç”¨å¼€å§‹
            elif kind == "on_tool_start":
                tool_name = event.get("name", "unknown")
                yield f"\nğŸ”§ æ­£åœ¨è°ƒç”¨ {tool_name}...\n"
            
            # å¤„ç†å·¥å…·è°ƒç”¨ç»“æŸ
            elif kind == "on_tool_end":
                yield "\nâœ… å·¥å…·è°ƒç”¨å®Œæˆ\n"
        
        # ä¿å­˜å¯¹è¯è®°å½•
        await self.memory.add_message("user", message)
        await self.memory.add_message("assistant", full_response)
        
        # å¼‚æ­¥åˆ†æå¹¶è¿›åŒ–
        await self._analyze_and_evolve(message, {"output": full_response})
    
    def _build_system_message(self, input_data: Dict[str, Any]) -> str:
        """æ„å»ºç³»ç»Ÿæ¶ˆæ¯å†…å®¹"""
        template = (
            LEARNING_COACH_PROMPT if self.mode == "coach"
            else READING_COMPANION_PROMPT
        )
        
        return template.format(
            user_profile=input_data.get("user_profile", "æ–°ç”¨æˆ·"),
            conversation_summary=input_data.get("conversation_summary", "æ–°å¯¹è¯"),
            current_time=input_data.get("current_time", ""),
            reading_context=input_data.get("reading_context", "æ— "),
        )
    
    def _prepare_input(
        self,
        message: str,
        context: Optional[Dict[str, Any]] = None,
    ) -> Dict[str, Any]:
        """å‡†å¤‡ Agent è¾“å…¥"""
        from datetime import datetime
        
        # è·å–ç”¨æˆ·ç”»åƒ
        user_profile = self.memory.get_user_profile_summary()
        
        # è·å–å¯¹è¯æ‘˜è¦
        conversation_summary = self.memory.get_conversation_summary()
        
        # è·å–èŠå¤©å†å²
        chat_history = self.memory.get_chat_history(limit=10)
        
        # æ„å»ºè¾“å…¥
        input_data = {
            "input": message,
            "chat_history": chat_history,
            "user_profile": user_profile,
            "conversation_summary": conversation_summary,
            "current_time": datetime.now().strftime("%Y-%m-%d %H:%M"),
        }
        
        # æ·»åŠ æ¨¡å¼ç‰¹å®šçš„ä¸Šä¸‹æ–‡
        if self.mode == "reader" and context:
            input_data["reading_context"] = json.dumps(
                context, ensure_ascii=False, indent=2
            )
        else:
            input_data["reading_context"] = "æ— "
        
        return input_data
    
    async def _analyze_and_evolve(
        self,
        user_message: str,
        result: Dict[str, Any],
    ):
        """
        åˆ†æå¯¹è¯å¹¶æ›´æ–°ç”¨æˆ·ç”»åƒï¼ˆè¿›åŒ–æœºåˆ¶ï¼‰
        
        è¿™æ˜¯ Agent è‡ªæˆ‘è¿›åŒ–çš„æ ¸å¿ƒï¼š
        1. åˆ†æç”¨æˆ·çš„å­¦ä¹ åå¥½
        2. è¯†åˆ«ç”¨æˆ·çš„çŸ¥è¯†æ°´å¹³
        3. è®°å½•ç”¨æˆ·çš„å…´è¶£é¢†åŸŸ
        4. ä¼˜åŒ–äº¤äº’ç­–ç•¥
        """
        try:
            # æå–å…³é”®ä¿¡æ¯
            insights = await self._extract_insights(user_message, result)
            
            if insights:
                # æ›´æ–°ç”¨æˆ·ç”»åƒ
                await self.memory.update_user_profile(insights)
                
        except Exception as e:
            # è¿›åŒ–å¤±è´¥ä¸å½±å“ä¸»æµç¨‹
            print(f"è¿›åŒ–åˆ†æå¤±è´¥: {e}")
    
    async def _extract_insights(
        self,
        user_message: str,
        result: Dict[str, Any],
    ) -> Optional[Dict[str, Any]]:
        """ä»å¯¹è¯ä¸­æå–ç”¨æˆ·æ´å¯Ÿ"""
        # ä½¿ç”¨ LLM åˆ†æå¯¹è¯
        analysis_prompt = f"""åˆ†æä»¥ä¸‹å¯¹è¯ï¼Œæå–ç”¨æˆ·å­¦ä¹ ç›¸å…³çš„æ´å¯Ÿï¼š

ç”¨æˆ·æ¶ˆæ¯: {user_message}
åŠ©æ‰‹å›å¤: {result.get('output', '')[:500]}

è¯·ä»¥ JSON æ ¼å¼è¿”å›æ´å¯Ÿï¼ˆå¦‚æœæ²¡æœ‰æœ‰ä»·å€¼çš„æ´å¯Ÿè¿”å› nullï¼‰ï¼š
{{
    "learning_style": "ç”¨æˆ·çš„å­¦ä¹ é£æ ¼åå¥½ï¼ˆå¦‚æœ‰ï¼‰",
    "knowledge_level": "ç”¨æˆ·åœ¨æŸé¢†åŸŸçš„çŸ¥è¯†æ°´å¹³ï¼ˆå¦‚æœ‰ï¼‰",
    "interests": ["ç”¨æˆ·æ„Ÿå…´è¶£çš„ä¸»é¢˜ï¼ˆå¦‚æœ‰ï¼‰"],
    "pain_points": ["ç”¨æˆ·é‡åˆ°çš„å›°éš¾ï¼ˆå¦‚æœ‰ï¼‰"],
    "preferences": "ç”¨æˆ·çš„äº¤äº’åå¥½ï¼ˆå¦‚æœ‰ï¼‰"
}}

åªè¿”å› JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚å¦‚æœæ²¡æœ‰æœ‰ä»·å€¼çš„æ´å¯Ÿï¼Œè¿”å› nullã€‚
"""
        
        try:
            response = await self.llm.ainvoke([HumanMessage(content=analysis_prompt)])
            content = response.content.strip()
            
            if content and content != "null":
                # å°è¯•è§£æ JSON
                if content.startswith("```"):
                    content = content.split("```")[1]
                    if content.startswith("json"):
                        content = content[4:]
                
                return json.loads(content)
        except Exception:
            pass
        
        return None
    
    async def get_suggestions(self) -> List[str]:
        """
        æ ¹æ®ç”¨æˆ·ç”»åƒç”Ÿæˆä¸ªæ€§åŒ–å»ºè®®
        
        è¿™æ˜¯è¿›åŒ–æœºåˆ¶çš„ä½“ç°ä¹‹ä¸€ï¼šæ ¹æ®ç§¯ç´¯çš„ç”¨æˆ·æ•°æ®æä¾›æ›´å¥½çš„å»ºè®®
        """
        profile = self.memory.get_user_profile()
        
        if not profile:
            return [
                "å¼€å§‹åˆ¶å®šä½ çš„å­¦ä¹ è®¡åˆ’å§ï¼",
                "å‘Šè¯‰æˆ‘ä½ æƒ³å­¦ä»€ä¹ˆ",
                "ä¸Šä¼ ä¸€å¼ é¢˜ç›®å›¾ç‰‡ï¼Œæˆ‘æ¥å¸®ä½ è§£ç­”",
            ]
        
        # æ ¹æ®ç”¨æˆ·ç”»åƒç”Ÿæˆä¸ªæ€§åŒ–å»ºè®®
        suggestions_prompt = f"""æ ¹æ®ä»¥ä¸‹ç”¨æˆ·ç”»åƒï¼Œç”Ÿæˆ3æ¡ä¸ªæ€§åŒ–çš„å­¦ä¹ å»ºè®®ï¼š

ç”¨æˆ·ç”»åƒ:
{json.dumps(profile, ensure_ascii=False, indent=2)}

è¦æ±‚ï¼š
1. å»ºè®®è¦å…·ä½“å¯æ‰§è¡Œ
2. ä¸ç”¨æˆ·çš„å­¦ä¹ ç›®æ ‡ç›¸å…³
3. è€ƒè™‘ç”¨æˆ·çš„å­¦ä¹ é£æ ¼

ä»¥ JSON æ•°ç»„æ ¼å¼è¿”å›ï¼Œæ¯æ¡å»ºè®®ä¸è¶…è¿‡20ä¸ªå­—ï¼š
["å»ºè®®1", "å»ºè®®2", "å»ºè®®3"]
"""
        
        try:
            response = await self.llm.ainvoke([HumanMessage(content=suggestions_prompt)])
            return json.loads(response.content.strip())
        except Exception:
            return ["ç»§ç»­åŠ æ²¹å­¦ä¹ ï¼", "ä¿æŒå­¦ä¹ èŠ‚å¥", "æœ‰é—®é¢˜éšæ—¶é—®æˆ‘"]
