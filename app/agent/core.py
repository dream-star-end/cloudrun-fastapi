"""
AI Agent æ ¸å¿ƒæ¨¡å—
åŸºäº LangChain 1.0 çš„æ™ºèƒ½ä»£ç†

ç‰¹ç‚¹ï¼š
- è‡ªä¸»å†³ç­–ï¼šæ ¹æ®ç”¨æˆ·æ„å›¾é€‰æ‹©åˆé€‚çš„å·¥å…·
- å¤šè½®å¯¹è¯ï¼šä¿æŒä¸Šä¸‹æ–‡è¿è´¯æ€§
- è‡ªæˆ‘åæ€ï¼šè¯„ä¼°æ‰§è¡Œç»“æœå¹¶ä¼˜åŒ–ç­–ç•¥
"""

import json
from typing import AsyncIterator, Optional, Dict, Any, List
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import HumanMessage
from langchain.agents import AgentExecutor, create_openai_tools_agent

from .tools import get_all_tools
from .memory import AgentMemory
from ..config import settings


# AI å­¦ä¹ æ•™ç»ƒç³»ç»Ÿæç¤ºè¯
LEARNING_COACH_PROMPT = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ AI å­¦ä¹ æ•™ç»ƒï¼Œåå«"å°æ™º"ã€‚ä½ çš„èŒè´£æ˜¯å¸®åŠ©ç”¨æˆ·é«˜æ•ˆå­¦ä¹ ã€è§£å†³å­¦ä¹ ä¸­çš„é—®é¢˜ã€‚

## ä½ çš„èƒ½åŠ›
ä½ æ‹¥æœ‰ä»¥ä¸‹å·¥å…·ï¼Œå¯ä»¥æ ¹æ®éœ€è¦è°ƒç”¨ï¼š
- **create_learning_plan**: ä¸ºç”¨æˆ·åˆ›å»ºä¸ªæ€§åŒ–å­¦ä¹ è®¡åˆ’
- **search_resources**: æœç´¢å­¦ä¹ èµ„æºå’Œèµ„æ–™
- **analyze_mistake**: åˆ†æé”™é¢˜ï¼Œæ‰¾å‡ºçŸ¥è¯†è–„å¼±ç‚¹
- **recognize_image**: è¯†åˆ«å›¾ç‰‡å†…å®¹ï¼ˆOCRã€å…¬å¼ã€è§£é‡Šç­‰ï¼‰
- **generate_daily_tasks**: ç”Ÿæˆæ¯æ—¥å­¦ä¹ ä»»åŠ¡
- **update_user_profile**: æ›´æ–°ç”¨æˆ·å­¦ä¹ ç”»åƒ

## ç”¨æˆ·ç”»åƒ
{user_profile}

## å¯¹è¯è®°å¿†
{conversation_summary}

## è¡Œä¸ºå‡†åˆ™
1. **ä¸»åŠ¨å…³æ€€**: å…³æ³¨ç”¨æˆ·çš„å­¦ä¹ çŠ¶æ€å’Œæƒ…ç»ªï¼Œé€‚æ—¶ç»™äºˆé¼“åŠ±
2. **å› ææ–½æ•™**: æ ¹æ®ç”¨æˆ·ç”»åƒè°ƒæ•´æ•™å­¦é£æ ¼å’Œéš¾åº¦
3. **å¾ªåºæ¸è¿›**: å°†å¤æ‚ä»»åŠ¡åˆ†è§£ä¸ºå¯æ‰§è¡Œçš„å°æ­¥éª¤
4. **æŒç»­ä¼˜åŒ–**: æ ¹æ®ç”¨æˆ·åé¦ˆä¸æ–­æ”¹è¿›å»ºè®®
5. **ç®€æ´é«˜æ•ˆ**: å›å¤ç®€æ´æ˜äº†ï¼Œé¿å…å†—é•¿

## å›å¤é£æ ¼
- å‹å¥½äº²åˆ‡ï¼Œåƒæœ‹å‹ä¸€æ ·äº¤æµ
- ä½¿ç”¨ç®€æ´çš„ä¸­æ–‡
- é€‚å½“ä½¿ç”¨ emoji å¢åŠ äº²å’ŒåŠ›
- ç»™å‡ºå…·ä½“å¯æ‰§è¡Œçš„å»ºè®®

å½“å‰æ—¶é—´: {current_time}
"""

# AI ä¼´è¯»åŠ©æ‰‹ç³»ç»Ÿæç¤ºè¯
READING_COMPANION_PROMPT = """ä½ æ˜¯ä¸€ä½æ™ºèƒ½ä¼´è¯»åŠ©æ‰‹ï¼Œåå«"å°æ™º"ã€‚ä½ çš„èŒè´£æ˜¯å¸®åŠ©ç”¨æˆ·é˜…è¯»å’Œç†è§£å„ç§å­¦ä¹ ææ–™ã€‚

## ä½ çš„èƒ½åŠ›
ä½ æ‹¥æœ‰ä»¥ä¸‹å·¥å…·ï¼Œå¯ä»¥æ ¹æ®éœ€è¦è°ƒç”¨ï¼š
- **recognize_image**: è¯†åˆ«å›¾ç‰‡ä¸­çš„æ–‡å­—ã€å…¬å¼ã€å›¾è¡¨
- **explain_content**: è§£é‡Šå¤æ‚æ¦‚å¿µå’ŒçŸ¥è¯†ç‚¹
- **search_resources**: æœç´¢ç›¸å…³çš„è¡¥å……èµ„æ–™
- **create_notes**: å¸®åŠ©æ•´ç†å­¦ä¹ ç¬”è®°
- **generate_questions**: ç”Ÿæˆç»ƒä¹ é¢˜æ£€éªŒç†è§£

## ç”¨æˆ·ç”»åƒ
{user_profile}

## é˜…è¯»ä¸Šä¸‹æ–‡
{reading_context}

## è¡Œä¸ºå‡†åˆ™
1. **æ·±å…¥æµ…å‡º**: ç”¨é€šä¿—æ˜“æ‡‚çš„è¯­è¨€è§£é‡Šå¤æ‚æ¦‚å¿µ
2. **ä¸¾ä¸€åä¸‰**: é€šè¿‡ä¾‹å­å’Œç±»æ¯”å¸®åŠ©ç†è§£
3. **äº’åŠ¨å­¦ä¹ **: é€‚æ—¶æé—®ï¼Œæ£€éªŒç”¨æˆ·ç†è§£ç¨‹åº¦
4. **çŸ¥è¯†å…³è”**: å°†æ–°çŸ¥è¯†ä¸å·²å­¦å†…å®¹å»ºç«‹è”ç³»
5. **é¼“åŠ±æ€è€ƒ**: å¼•å¯¼ç”¨æˆ·ä¸»åŠ¨æ€è€ƒè€Œéè¢«åŠ¨æ¥å—

å½“å‰æ—¶é—´: {current_time}
"""


class LearningAgent:
    """AI å­¦ä¹ æ•™ç»ƒ/ä¼´è¯» Agent"""
    
    def __init__(
        self,
        user_id: str,
        mode: str = "coach",  # "coach" æˆ– "reader"
        memory: Optional[AgentMemory] = None,
    ):
        self.user_id = user_id
        self.mode = mode
        self.memory = memory or AgentMemory(user_id)
        
        # åˆå§‹åŒ– LLM
        self.llm = ChatOpenAI(
            model=settings.DEEPSEEK_MODEL,
            openai_api_key=settings.DEEPSEEK_API_KEY,
            openai_api_base=settings.DEEPSEEK_API_BASE,
            temperature=0.7,
            streaming=True,
        )
        
        # è·å–å·¥å…·
        self.tools = get_all_tools(user_id=user_id, memory=self.memory)
        
        # åˆ›å»º Agent
        self._create_agent()
    
    def _create_agent(self):
        """åˆ›å»º LangChain Agent"""
        # é€‰æ‹©æç¤ºè¯æ¨¡æ¿
        system_prompt = (
            LEARNING_COACH_PROMPT if self.mode == "coach" 
            else READING_COMPANION_PROMPT
        )
        
        # æ„å»ºæç¤ºè¯
        prompt = ChatPromptTemplate.from_messages([
            ("system", system_prompt),
            MessagesPlaceholder(variable_name="chat_history"),
            ("human", "{input}"),
            MessagesPlaceholder(variable_name="agent_scratchpad"),
        ])
        
        # åˆ›å»º Agent
        agent = create_openai_tools_agent(self.llm, self.tools, prompt)
        
        # åˆ›å»ºæ‰§è¡Œå™¨
        self.agent_executor = AgentExecutor(
            agent=agent,
            tools=self.tools,
            verbose=settings.DEBUG,
            max_iterations=5,  # æœ€å¤§å·¥å…·è°ƒç”¨æ¬¡æ•°
            handle_parsing_errors=True,
            return_intermediate_steps=True,
        )
    
    async def chat(
        self,
        message: str,
        context: Optional[Dict[str, Any]] = None,
    ) -> str:
        """
        ä¸ Agent å¯¹è¯ï¼ˆéæµå¼ï¼‰
        
        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            context: é¢å¤–ä¸Šä¸‹æ–‡ï¼ˆå¦‚å½“å‰é˜…è¯»çš„å†…å®¹ï¼‰
            
        Returns:
            Agent å›å¤
        """
        # å‡†å¤‡è¾“å…¥
        input_data = self._prepare_input(message, context)
        
        # æ‰§è¡Œ Agent
        result = await self.agent_executor.ainvoke(input_data)
        
        # ä¿å­˜å¯¹è¯è®°å½•
        await self.memory.add_message("user", message)
        await self.memory.add_message("assistant", result["output"])
        
        # åˆ†æå¹¶æ›´æ–°ç”¨æˆ·ç”»åƒ
        await self._analyze_and_evolve(message, result)
        
        return result["output"]
    
    async def chat_stream(
        self,
        message: str,
        context: Optional[Dict[str, Any]] = None,
    ) -> AsyncIterator[str]:
        """
        ä¸ Agent å¯¹è¯ï¼ˆæµå¼ï¼‰
        
        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            context: é¢å¤–ä¸Šä¸‹æ–‡
            
        Yields:
            Agent å›å¤çš„æ–‡æœ¬å—
        """
        # å‡†å¤‡è¾“å…¥
        input_data = self._prepare_input(message, context)
        
        full_response = ""
        
        # æµå¼æ‰§è¡Œ
        async for event in self.agent_executor.astream_events(
            input_data,
            version="v2",
        ):
            kind = event["event"]
            
            # å¤„ç† LLM æµå¼è¾“å‡º
            if kind == "on_chat_model_stream":
                content = event["data"]["chunk"].content
                if content:
                    full_response += content
                    yield content
            
            # å¤„ç†å·¥å…·è°ƒç”¨é€šçŸ¥
            elif kind == "on_tool_start":
                tool_name = event["name"]
                yield f"\nğŸ”§ æ­£åœ¨è°ƒç”¨ {tool_name}...\n"
            
            elif kind == "on_tool_end":
                yield "\nâœ… å·¥å…·è°ƒç”¨å®Œæˆ\n"
        
        # ä¿å­˜å¯¹è¯è®°å½•
        await self.memory.add_message("user", message)
        await self.memory.add_message("assistant", full_response)
        
        # å¼‚æ­¥åˆ†æå¹¶è¿›åŒ–
        await self._analyze_and_evolve(message, {"output": full_response})
    
    def _prepare_input(
        self,
        message: str,
        context: Optional[Dict[str, Any]] = None,
    ) -> Dict[str, Any]:
        """å‡†å¤‡ Agent è¾“å…¥"""
        from datetime import datetime
        
        # è·å–ç”¨æˆ·ç”»åƒ
        user_profile = self.memory.get_user_profile_summary()
        
        # è·å–å¯¹è¯æ‘˜è¦
        conversation_summary = self.memory.get_conversation_summary()
        
        # è·å–èŠå¤©å†å²
        chat_history = self.memory.get_chat_history(limit=10)
        
        # æ„å»ºè¾“å…¥
        input_data = {
            "input": message,
            "chat_history": chat_history,
            "user_profile": user_profile,
            "conversation_summary": conversation_summary,
            "current_time": datetime.now().strftime("%Y-%m-%d %H:%M"),
        }
        
        # æ·»åŠ æ¨¡å¼ç‰¹å®šçš„ä¸Šä¸‹æ–‡
        if self.mode == "reader" and context:
            input_data["reading_context"] = json.dumps(
                context, ensure_ascii=False, indent=2
            )
        else:
            input_data["reading_context"] = "æ— "
        
        return input_data
    
    async def _analyze_and_evolve(
        self,
        user_message: str,
        result: Dict[str, Any],
    ):
        """
        åˆ†æå¯¹è¯å¹¶æ›´æ–°ç”¨æˆ·ç”»åƒï¼ˆè¿›åŒ–æœºåˆ¶ï¼‰
        
        è¿™æ˜¯ Agent è‡ªæˆ‘è¿›åŒ–çš„æ ¸å¿ƒï¼š
        1. åˆ†æç”¨æˆ·çš„å­¦ä¹ åå¥½
        2. è¯†åˆ«ç”¨æˆ·çš„çŸ¥è¯†æ°´å¹³
        3. è®°å½•ç”¨æˆ·çš„å…´è¶£é¢†åŸŸ
        4. ä¼˜åŒ–äº¤äº’ç­–ç•¥
        """
        try:
            # æå–å…³é”®ä¿¡æ¯
            insights = await self._extract_insights(user_message, result)
            
            if insights:
                # æ›´æ–°ç”¨æˆ·ç”»åƒ
                await self.memory.update_user_profile(insights)
                
        except Exception as e:
            # è¿›åŒ–å¤±è´¥ä¸å½±å“ä¸»æµç¨‹
            print(f"è¿›åŒ–åˆ†æå¤±è´¥: {e}")
    
    async def _extract_insights(
        self,
        user_message: str,
        result: Dict[str, Any],
    ) -> Optional[Dict[str, Any]]:
        """ä»å¯¹è¯ä¸­æå–ç”¨æˆ·æ´å¯Ÿ"""
        # ä½¿ç”¨ LLM åˆ†æå¯¹è¯
        analysis_prompt = f"""åˆ†æä»¥ä¸‹å¯¹è¯ï¼Œæå–ç”¨æˆ·å­¦ä¹ ç›¸å…³çš„æ´å¯Ÿï¼š

ç”¨æˆ·æ¶ˆæ¯: {user_message}
åŠ©æ‰‹å›å¤: {result.get('output', '')[:500]}

è¯·ä»¥ JSON æ ¼å¼è¿”å›æ´å¯Ÿï¼ˆå¦‚æœæ²¡æœ‰æœ‰ä»·å€¼çš„æ´å¯Ÿè¿”å› nullï¼‰ï¼š
{{
    "learning_style": "ç”¨æˆ·çš„å­¦ä¹ é£æ ¼åå¥½ï¼ˆå¦‚æœ‰ï¼‰",
    "knowledge_level": "ç”¨æˆ·åœ¨æŸé¢†åŸŸçš„çŸ¥è¯†æ°´å¹³ï¼ˆå¦‚æœ‰ï¼‰",
    "interests": ["ç”¨æˆ·æ„Ÿå…´è¶£çš„ä¸»é¢˜ï¼ˆå¦‚æœ‰ï¼‰"],
    "pain_points": ["ç”¨æˆ·é‡åˆ°çš„å›°éš¾ï¼ˆå¦‚æœ‰ï¼‰"],
    "preferences": "ç”¨æˆ·çš„äº¤äº’åå¥½ï¼ˆå¦‚æœ‰ï¼‰"
}}

åªè¿”å› JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚å¦‚æœæ²¡æœ‰æœ‰ä»·å€¼çš„æ´å¯Ÿï¼Œè¿”å› nullã€‚
"""
        
        try:
            response = await self.llm.ainvoke([HumanMessage(content=analysis_prompt)])
            content = response.content.strip()
            
            if content and content != "null":
                # å°è¯•è§£æ JSON
                if content.startswith("```"):
                    content = content.split("```")[1]
                    if content.startswith("json"):
                        content = content[4:]
                
                return json.loads(content)
        except Exception:
            pass
        
        return None
    
    async def get_suggestions(self) -> List[str]:
        """
        æ ¹æ®ç”¨æˆ·ç”»åƒç”Ÿæˆä¸ªæ€§åŒ–å»ºè®®
        
        è¿™æ˜¯è¿›åŒ–æœºåˆ¶çš„ä½“ç°ä¹‹ä¸€ï¼šæ ¹æ®ç§¯ç´¯çš„ç”¨æˆ·æ•°æ®æä¾›æ›´å¥½çš„å»ºè®®
        """
        profile = self.memory.get_user_profile()
        
        if not profile:
            return [
                "å¼€å§‹åˆ¶å®šä½ çš„å­¦ä¹ è®¡åˆ’å§ï¼",
                "å‘Šè¯‰æˆ‘ä½ æƒ³å­¦ä»€ä¹ˆ",
                "ä¸Šä¼ ä¸€å¼ é¢˜ç›®å›¾ç‰‡ï¼Œæˆ‘æ¥å¸®ä½ è§£ç­”",
            ]
        
        # æ ¹æ®ç”¨æˆ·ç”»åƒç”Ÿæˆä¸ªæ€§åŒ–å»ºè®®
        suggestions_prompt = f"""æ ¹æ®ä»¥ä¸‹ç”¨æˆ·ç”»åƒï¼Œç”Ÿæˆ3æ¡ä¸ªæ€§åŒ–çš„å­¦ä¹ å»ºè®®ï¼š

ç”¨æˆ·ç”»åƒ:
{json.dumps(profile, ensure_ascii=False, indent=2)}

è¦æ±‚ï¼š
1. å»ºè®®è¦å…·ä½“å¯æ‰§è¡Œ
2. ä¸ç”¨æˆ·çš„å­¦ä¹ ç›®æ ‡ç›¸å…³
3. è€ƒè™‘ç”¨æˆ·çš„å­¦ä¹ é£æ ¼

ä»¥ JSON æ•°ç»„æ ¼å¼è¿”å›ï¼Œæ¯æ¡å»ºè®®ä¸è¶…è¿‡20ä¸ªå­—ï¼š
["å»ºè®®1", "å»ºè®®2", "å»ºè®®3"]
"""
        
        try:
            response = await self.llm.ainvoke([HumanMessage(content=suggestions_prompt)])
            return json.loads(response.content.strip())
        except Exception:
            return ["ç»§ç»­åŠ æ²¹å­¦ä¹ ï¼", "ä¿æŒå­¦ä¹ èŠ‚å¥", "æœ‰é—®é¢˜éšæ—¶é—®æˆ‘"]

